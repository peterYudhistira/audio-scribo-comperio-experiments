{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports go here\n",
    "import numpy as np\n",
    "import db\n",
    "import pandas as pd\n",
    "import inflect\n",
    "import string\n",
    "import nltk\n",
    "import gensim\n",
    "import contractions\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora, models\n",
    "from nltk.test.gensim_fixt import setup_module\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# this is where everything we've experimented on will be implemented.\n",
    "\n",
    "\n",
    "class AnomalyDetector():\n",
    "    def __init__(self, dbName: str = \"\",  dh=None, model=None, modelName=\"glove-wiki-gigaword-300\") -> None:\n",
    "        if dh is None:\n",
    "            self.dh = db.DatabaseHandler(dbName=dbName)\n",
    "        else:\n",
    "            self.dh = dh\n",
    "        if model is None:\n",
    "            if modelName != \"\":\n",
    "                self.model = api.load(modelName)\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "        self.FeatureExtractionParams = {}\n",
    "        self.AnomalyDetectionParams = {}\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - dh : DatabaseHandler --> to retrieve data from database\n",
    "    - eventID : int --> we're doing this by event, so straight to the eventID\n",
    "    - selector : str --> pretty much formality.\n",
    "    - splitBySentences : bool --> Split each doc into sentences or not. Defaults to no.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    None, just setting\n",
    "    '''\n",
    "\n",
    "    def SetDFFromDB(self, eventID: int, selector: str = \"event_id\", splitBySentences: bool = False):\n",
    "        self.df = self.dh.get_recordDataJoinedDF(selector=selector, ID=eventID)\n",
    "        if splitBySentences:\n",
    "            # df.set_index('id', inplace=True)\n",
    "            self.df['answer'] = self.df['answer'].str.split('.')\n",
    "            self.df = self.df.explode(\"answer\", True)\n",
    "            self.df.drop(self.df[self.df[\"answer\"] == \"\"].index, inplace=True)\n",
    "            self.df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # ditto above, but takes a pre-made DF instead.\n",
    "    def SetDF(self, df: db.pd.DataFrame, splitBySentences: bool = False):\n",
    "        self.df = df\n",
    "        if splitBySentences:\n",
    "            # df.set_index('id', inplace=True)\n",
    "            self.df['answer'] = self.df['answer'].str.split('.')\n",
    "            self.df = self.df.explode(\"answer\", True)\n",
    "            self.df.drop(self.df[self.df[\"answer\"] == \"\"].index, inplace=True)\n",
    "            self.df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def SetModel(self, modelName: str = \"glove-wiki-gigaword-300\"):\n",
    "        self.model = api.load(modelName)\n",
    "\n",
    "    # these are to add key:value to the dictionaries that dictate parameters. Indeed, we are refurbishing.\n",
    "    def SetFeatureExtractionParam(self, key: str, value):\n",
    "        self.FeatureExtractionParams[key] = value\n",
    "\n",
    "    def SetAnomalyDetectionParam(self, key: str, value):\n",
    "        self.AnomalyDetectionParams[key] = value\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - dh : DatabaseHandler --> to retrieve data from database\n",
    "    - eventID : int --> we're doing this by event, so straight to the eventID\n",
    "    - selector : str --> pretty much formality.\n",
    "    - splitBySentences : bool --> Split each doc into sentences or not. Defaults to no.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - df : DataFrame --> dataframe containing the thing we're gonna be using.\n",
    "    '''\n",
    "\n",
    "    def GetDF(self, dh: db.DatabaseHandler, eventID: int, selector: str = \"event_id\", splitBySentences: bool = False):\n",
    "        df = dh.get_recordDataJoinedDF(selector=selector, ID=eventID)\n",
    "        if splitBySentences:\n",
    "            # df.set_index('id', inplace=True)\n",
    "            df['answer'] = df['answer'].str.split('.')\n",
    "            df = df.explode(\"answer\", True)\n",
    "            df.drop(df[df[\"answer\"] == \"\"].index, inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - doc : str --> a string representing a sentence/document.\n",
    "    - isLemma : bool --> use lemmatizer or not? Defaults to not.\n",
    "    - isStopWords : bool --> use stopwords or not? Defaults to not.\n",
    "    - isInflect : bool --> use inflections (you're --> you are) or not? Defaults to not.\n",
    "    - isNumberFiltered :  bool --> delete numbers in the string? Defaults to yes. \n",
    "    '''\n",
    "    '''\n",
    "    output : list<str> --> a list of word tokens (list<string>)\n",
    "    '''\n",
    "\n",
    "    def PreprocessDocument(self, doc: str, isLemma: bool = False, isStopWords: bool = False, isInflect: bool = False, isNumberFiltered: bool = True):\n",
    "        inflector = inflect.engine()\n",
    "        stopwordSet = set(stopwords.words(\"english\"))\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        punctuations = string.punctuation\n",
    "        # if numbers are filtered, add that to the punctuation string\n",
    "        if isNumberFiltered:\n",
    "            punctuations += \"1234567890\"\n",
    "\n",
    "        # case fold\n",
    "        doc = doc.lower()\n",
    "\n",
    "        # remove puncs\n",
    "        doc = \"\".join([char for char in doc if char not in punctuations])\n",
    "\n",
    "        # tokenize it.\n",
    "        token_list = nltk.word_tokenize(doc)\n",
    "\n",
    "        for i in range(len(token_list)):\n",
    "            # if inflect\n",
    "            if isInflect:\n",
    "                if token_list[i].isdigit():\n",
    "                    token_list[i] = inflector.number_to_words(token_list[i])\n",
    "\n",
    "            # if lemma\n",
    "            if isLemma:\n",
    "                tagged_word = nltk.pos_tag([token_list[i]])\n",
    "                wordnet_pos = self.getWordnetPos(tagged_word[0][1])\n",
    "                token_list[i] = lemmatizer.lemmatize(\n",
    "                    tagged_word[0][0], pos=wordnet_pos)\n",
    "\n",
    "            # if stopword\n",
    "            if isStopWords:\n",
    "                if token_list[i] in stopwordSet or token_list[i].isdigit():\n",
    "                    token_list[i] = \"#\"  # mark as #\n",
    "\n",
    "        # remove the marked strings\n",
    "        token_list = [token for token in token_list if token != \"#\"]\n",
    "\n",
    "        if token_list:\n",
    "            return token_list\n",
    "        return [\"\"]\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - tag : str --> the tag obtained from POS tagging.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - str --> Wordnet POS tag.\n",
    "    '''\n",
    "\n",
    "    def getWordnetPos(self, tag):\n",
    "        \"\"\"Map POS tag to WordNet POS tag\"\"\"\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN  # solves as noun by default.\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - doclist : list<str> --> list of doc/sentences.\n",
    "    - isProcessed : bool --> has it already been preprocessed? Defaults to True.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - df_tfidf : Dataframe --> the TFIDF matrix in df form. \n",
    "    - matrix : matrix --> the TFIDF matrix purely. mainly for LDA purposes.\n",
    "    '''\n",
    "\n",
    "    def GetTFIDF(self, doclist: list, isPreprocessed=True):\n",
    "        if not isPreprocessed:\n",
    "            doclist = [self.PreprocessDocument(\n",
    "                doc, isLemma=True, isStopWords=True) for doc in doclist]\n",
    "        # else:\n",
    "        #     # just tokenize the thing\n",
    "        #     doclist = [nltk.word_tokenize(doc) for doc in doclist]\n",
    "        # i think the thing has already been tokenized. That's the problem.\n",
    "        flat_doclist = [' '.join(doc)\n",
    "                        for doc in doclist]  # turn into one big corpus\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        matrix = vectorizer.fit_transform(flat_doclist)\n",
    "        tfidf_keys = vectorizer.get_feature_names_out()\n",
    "        df_tfidf = db.pd.DataFrame(matrix.toarray(), columns=tfidf_keys)\n",
    "\n",
    "        return df_tfidf, matrix\n",
    "\n",
    "    # input : list<str> : tokens of one document/sentence\n",
    "    # output : list<(str, list<int>[300])> : list of word-vector pair for each word available on the model\n",
    "    def WordEmbed(self, document: list, model):\n",
    "        word_embed_pairs = []\n",
    "        for word in document:\n",
    "            if word in model:\n",
    "                word_embed_pairs.append((word, model[word]))\n",
    "        return word_embed_pairs\n",
    "\n",
    "    # input : list<(str, list<float>[300])>, str : word-vector pair list and preferred agg method.\n",
    "    # output : list<float>[300] : 300-d vector that represents an aggregated value of the input words\n",
    "    def SentenceEmbedUnweightedFunction(self, word_embed_pair_list: list, aggregateMethod: str = \"avg\"):\n",
    "        wvs = []\n",
    "        for pair in word_embed_pair_list:\n",
    "            wvs.append(pair[1])\n",
    "        if aggregateMethod == \"avg\":\n",
    "            return np.mean(wvs, axis=0)\n",
    "        else:\n",
    "            return np.sum(wvs, axis=0)\n",
    "\n",
    "    # input : list<list<(str, list<float>[300])>>, str : list containing word-vector pairs and preferred agg method\n",
    "    # output : list<(str, list<int>[300])> : list containing sentence-vector pairs.\n",
    "    def SentenceEmbedUnweighted(self, word_embedded_docs: list, aggregateMethod: str = \"avg\"):\n",
    "        sentence_embedded_docs = []\n",
    "        for i in range(len(word_embedded_docs)):\n",
    "            sentence_embedded_docs.append(self.SentenceEmbedUnweightedFunction(\n",
    "                word_embedded_docs[i], aggregateMethod))\n",
    "        return sentence_embedded_docs\n",
    "\n",
    "    '''\n",
    "    input :\n",
    "    list<list<(str, list<float>[300])>> : word-vector pair list\n",
    "    matrix : tf-idf matrix for the corresponding doc\n",
    "    int : the row we want\n",
    "    str : preferred agg method\n",
    "    '''\n",
    "    # output : list<float>[300] : 300-d vector that represents an aggregated value of the input words\n",
    "\n",
    "    def SentenceEmbedWeightedFunction(self, word_embed_pair_list: list, tfidf_matrix, index: int, aggregateMethod: str = \"avg\"):\n",
    "        weighted_wvs = []\n",
    "        # multiplies each word with its TF-IDF value in the corresponding row. Is 0 if word isn't found somehow.\n",
    "        for pair in word_embed_pair_list:\n",
    "            tfidf_weight = 0\n",
    "            if pair[0] in tfidf_matrix:\n",
    "                tfidf_weight = tfidf_matrix[pair[0]][index]\n",
    "            weighted_wvs.append(pair[1] * tfidf_weight)\n",
    "        # turn into array for fast aggregating\n",
    "        weighted_wvs = np.array(weighted_wvs)\n",
    "        if aggregateMethod == \"avg\":\n",
    "            sentence_vector = np.mean(weighted_wvs, axis=0)\n",
    "        else:\n",
    "            sentence_vector = np.sum(weighted_wvs, axis=0)\n",
    "        return sentence_vector\n",
    "\n",
    "    # input : list<list<(str, list<float>[300])>>, str : list containing word-vector pairs, TF-IDF matrix of the corpus, and preferred agg method\n",
    "    # output : list<(str, list<float>[300])> : list containing sentence-vector pairs.\n",
    "    def SentenceEmbedWeighted(self, word_embedded_docs: list, tfidf_matrix, aggregateMethod=\"avg\"):\n",
    "        sentence_embedded_docs = []\n",
    "        for i in range(len(word_embedded_docs)):\n",
    "            sentence_embedded_docs.append(self.SentenceEmbedWeightedFunction(\n",
    "                word_embedded_docs[i], tfidf_matrix, i, aggregateMethod))\n",
    "        return sentence_embedded_docs\n",
    "\n",
    "    '''\n",
    "    input:\n",
    "    - doclist : list<list<str>> --> list of tokenized sentences/docs\n",
    "    - topics : int --> number of inferred topics.\n",
    "    - use_tfidf : bool --> use TFIDF or not? defaults to yes.\n",
    "    '''\n",
    "    '''\n",
    "    output:\n",
    "    - docFeatureList : list<list<float>> --> topic distribution for each sentence/doc\n",
    "    '''\n",
    "\n",
    "    def GetLDADistribution(self, doclist: list, topics: int = 5, use_tfidf: bool = True):\n",
    "        new_corpus = []\n",
    "\n",
    "        if use_tfidf:\n",
    "            for i in range(len(doclist)):\n",
    "                doc = [(j, self.tfidf_matrix[i, j])\n",
    "                       for j in self.tfidf_matrix[i].indices]\n",
    "                new_corpus.append(doc)\n",
    "                gensim_dict = corpora.Dictionary.from_corpus(new_corpus)\n",
    "        else:\n",
    "            gensim_dict = corpora.Dictionary(doclist)\n",
    "            new_corpus = [gensim_dict.doc2bow(doc) for doc in doclist]\n",
    "\n",
    "        lda_model = gensim.models.LdaModel(\n",
    "            new_corpus, num_topics=topics, id2word=gensim_dict)\n",
    "        goofy_ahh_doc_topic_distributions = lda_model[new_corpus]\n",
    "\n",
    "        docFeatureList = []\n",
    "        for doc_topic_dist in goofy_ahh_doc_topic_distributions:\n",
    "            featureList = [0.0 for i in range(0, topics)]\n",
    "            for topic_dist in doc_topic_dist:\n",
    "                featureList[topic_dist[0]] = topic_dist[1]\n",
    "            docFeatureList.append(featureList)\n",
    "\n",
    "        return docFeatureList\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - vectors : list<list<float>> --> list of features corresponding to each doc/sentence\n",
    "    - epsilon : float --> the radius within which points are considered connected.\n",
    "    - min : int --> minimum amount of connected points for a point to be considered a core point of a cluster.\n",
    "    '''\n",
    "    '''\n",
    "    output:\n",
    "    clusters : list<int> --> a list of integers to assign each data point to a cluster. -1 means outlier.\n",
    "    '''\n",
    "\n",
    "    def GetDBSCANClusters(self, vectors, epsilon: float, min: int):\n",
    "        dbscan = DBSCAN(eps=epsilon, min_samples=min)\n",
    "        clusters = dbscan.fit_predict(vectors)\n",
    "        # plt.title(\"to the depths of depravity {} and the cusp of blasphemy {}.\".format(epsilon, min))\n",
    "        # plt.scatter(vectors[:, 0], vectors[:, 1], c=clusters)\n",
    "        # plt.show()\n",
    "        # print(clusters)\n",
    "        return clusters\n",
    "    '''\n",
    "    inputs:\n",
    "    - vectors : list<list<float>> --> list of features corresponding to each doc/sentence\n",
    "\n",
    "    '''\n",
    "\n",
    "    def GetIFResults(self, vector):\n",
    "        isolationForest = IsolationForest(n_estimators=500, contamination=0.1)\n",
    "        isolationForest.fit(vector)\n",
    "        IFResults = isolationForest.decision_function(vector)\n",
    "\n",
    "        # minus values yield anomalies.\n",
    "        for i in range(len(IFResults)):\n",
    "            if IFResults[i] >= 0:\n",
    "                IFResults[i] = 0\n",
    "            else:\n",
    "                IFResults[i] = -1\n",
    "        return IFResults\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - clusters : list<int> --> a list of clusters assigned to each doc/sentence\n",
    "    - df : DataFrame --> the dataframe in question\n",
    "    - isReturnSeparate : bool --> split return or not. Defaults to split (for some reason...)\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - dfOutliers : DataFrame --> the dataframe whose answers have been marked as outliers.\n",
    "    - dfGoods : DataFrame --> the dataframe whose answers have not been marked as outliers.\n",
    "    '''\n",
    "\n",
    "    def ReturnClusters(self, isReturnSeparate: bool = True):\n",
    "        if isReturnSeparate:\n",
    "            dfGoods = self.df.loc[self.df[\"Cluster Assignment\"] != -1]\n",
    "            dfOutliers = self.df.loc[self.df[\"Cluster Assignment\"] == -1]\n",
    "            return dfOutliers, dfGoods\n",
    "        else:\n",
    "            if self.df.isnull().values.any():\n",
    "                self.df.reset_index(inplace=True)\n",
    "            return self.df\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - method : str --> LDA or Embedding.\n",
    "    - isWeighted : bool --> use weights or not\n",
    "    - nTopics : int --> for LDA.\n",
    "    '''\n",
    "    '''\n",
    "    - outputs : none. This is an internal function\n",
    "    '''\n",
    "    def GetAnomalies(self, isReturnSeparate: bool = False):\n",
    "        self.SetDocumentTokens()  # set tokens in the DF\n",
    "        if self.FeatureExtractionParams[\"method\"] == \"embedding\":\n",
    "            self.SetEmbeddingResult()\n",
    "        elif self.FeatureExtractionParams[\"method\"] == \"LDA\":\n",
    "            self.SetLDAResult()\n",
    "\n",
    "        if self.AnomalyDetectionParams[\"algorithm\"] == \"DBSCAN\":\n",
    "            self.SetDBSCANClusters(list(self.df[\"Document Embed\"]))\n",
    "        elif self.AnomalyDetectionParams[\"algorithm\"] == \"LOF\":\n",
    "            self.SetLOFClusters(list(self.df[\"Document Embed\"]))\n",
    "        elif self.AnomalyDetectionParams[\"algorithm\"] == \"IF\":\n",
    "            self.SetIFClusters(list(self.df[\"Document Embed\"]))\n",
    "\n",
    "        return self.ReturnClusters(isReturnSeparate=isReturnSeparate)\n",
    "\n",
    "    def GetAnomalies_IsolationForest_Embedding(self, isWeighted: bool = True, aggregateMethod: str = \"avg\", isReturnSeparate: bool = True):\n",
    "        # df and model are obtained by invoking a separate function, and it is assumed to be already available when invoking this function.\n",
    "\n",
    "        # preprocess each doc/sentence\n",
    "        self.preprocessedDocs = [self.PreprocessDocument(\n",
    "            doc, isLemma=True, isStopWords=True) for doc in self.df[\"answer\"]]\n",
    "\n",
    "        # extract feature with embedding\n",
    "        self.wordEmbeddedDocs = [self.WordEmbed(\n",
    "            doc, self.model) for doc in self.preprocessedDocs]\n",
    "\n",
    "        # if weighted, prepare TF-IDF and embed sentences with weight.\n",
    "        if isWeighted:\n",
    "            self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                self.preprocessedDocs)\n",
    "            self.doc_embeds = self.SentenceEmbedWeighted(\n",
    "                self.wordEmbeddedDocs, self.tfidf_df, aggregateMethod)\n",
    "        else:\n",
    "            self.doc_embeds = self.SentenceEmbedUnweighted(\n",
    "                self.wordEmbeddedDocs, aggregateMethod)\n",
    "\n",
    "        # append embedding to each document\n",
    "        if self.doc_embeds:\n",
    "            self.df[\"Document Embed\"] = self.doc_embeds\n",
    "            # preventing NaN in the simplest fucking way in know.\n",
    "            self.df = self.df.dropna(subset=[\"Document Embed\"])\n",
    "\n",
    "        # apply Isolation Forest\n",
    "        self.ifResults = self.GetIFResults(\n",
    "            vector=list(self.df[\"Document Embed\"]))\n",
    "\n",
    "        return self.ReturnClusters(self.ifResults, self.df, isReturnSeparate=isReturnSeparate)\n",
    "\n",
    "    '''\n",
    "    inputs  : None (checks self.FeatureExtractionParams)\n",
    "    desc    : embeds each doc and put it in a new column \"Document Embed\"\n",
    "    '''\n",
    "\n",
    "    def SetEmbeddingResult(self):\n",
    "        # extract feature with embedding\n",
    "        self.wordEmbeddedDocs = [self.WordEmbed(\n",
    "            doc, self.model) for doc in self.preprocessedDocs]\n",
    "\n",
    "        if \"weighted\" in self.FeatureExtractionParams:\n",
    "            self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                self.preprocessedDocs)\n",
    "            self.doc_embeds = self.SentenceEmbedWeighted(\n",
    "                self.wordEmbeddedDocs, self.tfidf_df, self.FeatureExtractionParams[\"aggregate_method\"])\n",
    "        else:\n",
    "            self.doc_embeds = self.SentenceEmbedUnweighted(\n",
    "                self.wordEmbeddedDocs, self.FeatureExtractionParams[\"aggregate_method\"])\n",
    "\n",
    "        self.df[\"Document Embed\"] = self.doc_embeds\n",
    "\n",
    "    def SetDefaultParams(self):\n",
    "        # here we will put the default params\n",
    "        self.SetFeatureExtractionParam(\"method\", \"embedding\")\n",
    "        self.SetFeatureExtractionParam(\"weighted\", True)\n",
    "        self.SetFeatureExtractionParam(\"condense\", False)\n",
    "        self.SetFeatureExtractionParam(\"n_topics\", 5)\n",
    "        self.SetFeatureExtractionParam(\"aggregate_method\", \"avg\")\n",
    "        self.SetAnomalyDetectionParam(\"algorithm\", \"DBSCAN\")\n",
    "        self.SetAnomalyDetectionParam(\"epsilon\", 1.0)\n",
    "        self.SetAnomalyDetectionParam(\"minsamp\", 2)\n",
    "        self.SetAnomalyDetectionParam(\"epsilon\", 1.0)\n",
    "        self.SetAnomalyDetectionParam(\"algorithm\", \"IF\")\n",
    "        self.SetAnomalyDetectionParam(\"estimators\", 500)\n",
    "        self.SetAnomalyDetectionParam(\"contamination\", 0.1)\n",
    "        self.SetAnomalyDetectionParam(\"neighbors\", 5)\n",
    "\n",
    "    # preprocess each doc/sentence\n",
    "    def SetDocumentTokens(self):\n",
    "        self.preprocessedDocs = [self.PreprocessDocument(\n",
    "            doc, isLemma=True, isStopWords=True) for doc in self.df[\"answer\"]]\n",
    "        self.df[\"Tokenized\"] = self.preprocessedDocs\n",
    "\n",
    "        # if cut off data with less than x values\n",
    "        if \"prune\" in self.FeatureExtractionParams:\n",
    "            mask = self.df['Embedded Docs'].apply(\n",
    "                lambda x: len(x) > self.FeatureExtractionParams[\"prune\"])\n",
    "            self.df = self.df[mask]\n",
    "\n",
    "    '''\n",
    "    inputs  : None (checks self.FeatureExtractionParams)\n",
    "    desc    : assigns topic distribution for each document.\n",
    "    '''\n",
    "\n",
    "    def SetLDAResult(self):\n",
    "        doclist = list(self.df[\"Tokenized\"])\n",
    "        new_corpus = []\n",
    "        if self.FeatureExtractionParams[\"weighted\"]:\n",
    "            self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                self.preprocessedDocs)\n",
    "            for i in range(len(doclist)):\n",
    "                doc = [(j, self.tfidf_matrix[i, j])\n",
    "                       for j in self.tfidf_matrix[i].indices]\n",
    "                new_corpus.append(doc)\n",
    "                gensim_dict = corpora.Dictionary.from_corpus(new_corpus)\n",
    "        else:\n",
    "            gensim_dict = corpora.Dictionary(doclist)\n",
    "            new_corpus = [gensim_dict.doc2bow(doc) for doc in doclist]\n",
    "\n",
    "        lda_model = gensim.models.LdaModel(\n",
    "            new_corpus, num_topics=self.FeatureExtractionParams[\"n_topics\"], id2word=gensim_dict)\n",
    "        goofy_ahh_doc_topic_distributions = lda_model[new_corpus]\n",
    "\n",
    "        docFeatureList = []\n",
    "        for doc_topic_dist in goofy_ahh_doc_topic_distributions:\n",
    "            featureList = [0.0 for i in range(\n",
    "                0, self.FeatureExtractionParams[\"n_topics\"])]\n",
    "            for topic_dist in doc_topic_dist:\n",
    "                featureList[topic_dist[0]] = topic_dist[1]\n",
    "            docFeatureList.append(featureList)\n",
    "\n",
    "        self.df[\"Document Embed\"] = docFeatureList\n",
    "\n",
    "    '''\n",
    "    inputs  :\n",
    "    - vectors : list<list<float>> --> list of features corresponding to each doc/sentence\n",
    "    desc    : assigns cluster via DBSCAN. \n",
    "    '''\n",
    "\n",
    "    def SetDBSCANClusters(self, vectors):\n",
    "        dbscan = DBSCAN(\n",
    "            eps=self.AnomalyDetectionParams[\"epsilon\"], min_samples=self.AnomalyDetectionParams[\"minsamp\"])\n",
    "        clusters = dbscan.fit_predict(vectors)\n",
    "        self.df[\"Cluster Assignment\"] = clusters\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - vectors : list<list<float>> --> list of features corresponding to each doc/sentence\n",
    "\n",
    "    '''\n",
    "\n",
    "    def SetIFClusters(self, vector):\n",
    "        isolationForest = IsolationForest(\n",
    "            n_estimators=self.AnomalyDetectionParams[\"estimators\"], contamination=self.AnomalyDetectionParams[\"contamination\"])\n",
    "        isolationForest.fit(vector)\n",
    "        IFResults = isolationForest.decision_function(vector)\n",
    "\n",
    "        # minus values yield anomalies.\n",
    "        for i in range(len(IFResults)):\n",
    "            if IFResults[i] >= 0:\n",
    "                IFResults[i] = 0\n",
    "            else:\n",
    "                IFResults[i] = -1\n",
    "        self.df[\"Cluster Assignment\"] = IFResults\n",
    "\n",
    "    '''\n",
    "    inputs : vectors : list<list<float>> --> list of features for each doc/sentence\n",
    "    '''\n",
    "\n",
    "    def SetLOFClusters(self, vector):\n",
    "        lof = LocalOutlierFactor(\n",
    "            n_neighbors=self.AnomalyDetectionParams[\"neighbors\"], contamination=self.AnomalyDetectionParams[\"contamination\"])\n",
    "        lof.fit(vector)\n",
    "        LOFResults = lof.negative_outlier_factor_\n",
    "\n",
    "        # minus values yield anomalies\n",
    "        LOFResults[LOFResults >= 0] = 0\n",
    "        LOFResults[LOFResults < 0] = -1\n",
    "        self.df[\"Cluster Assignment\"] = LOFResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = db.DatabaseHandler(\"testdb.db\")\n",
    "ad = AnomalyDetector(dh=dh, modelName=\"\")\n",
    "ad.SetDefaultParams()\n",
    "ad.SetDFFromDB(eventID=19, splitBySentences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'LDA',\n",
       " 'weighted': True,\n",
       " 'condense': False,\n",
       " 'n_topics': 5,\n",
       " 'aggregate_method': 'avg'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ad.SetAnomalyDetectionParam(\"algorithm\", \"LOF\")\n",
    "ad.SetAnomalyDetectionParam(\"estimators\", 500)\n",
    "ad.SetAnomalyDetectionParam(\"contamination\", 0.01)\n",
    "ad.SetAnomalyDetectionParam(\"neighbors\", 5)\n",
    "ad.SetFeatureExtractionParam(\"method\", \"LDA\")\n",
    "ad.FeatureExtractionParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Document Embed</th>\n",
       "      <th>Cluster Assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>KNC</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Yeah, of course. Of course I think I'm a sinn...</td>\n",
       "      <td>[yeah, course, course, think, im, sinner, cour...</td>\n",
       "      <td>[0.82050496, 0.04580212, 0.044529807, 0.044915...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>RIC</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>In my opinion, all sins can be forgiven But i...</td>\n",
       "      <td>[opinion, sin, forgiven, catholicism, sin, for...</td>\n",
       "      <td>[0.042426735, 0.043015417, 0.8289398, 0.043271...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Human error is a sin. Everything improper is sin.</td>\n",
       "      <td>[human, error, sin, everything, improper, sin]</td>\n",
       "      <td>[0.062398467, 0.062497832, 0.7499888, 0.062658...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>PY</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>If a man defies a God then he sins. A mistake ...</td>\n",
       "      <td>[man, defies, god, sin, mistake, accident, sin...</td>\n",
       "      <td>[0.7822442, 0.054201584, 0.05532552, 0.0549448...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Maybe a sin is a mistake done with evil intent.</td>\n",
       "      <td>[maybe, sin, mistake, evil, intent]</td>\n",
       "      <td>[0.06398887, 0.7434575, 0.064547785, 0.0640989...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>TMS</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Sin is commited. Mistake is incidental.</td>\n",
       "      <td>[sin, commit, mistake, incidental]</td>\n",
       "      <td>[0.06953028, 0.06986823, 0.72250396, 0.0692189...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Sin is maybe knowing that your actions have co...</td>\n",
       "      <td>[sin, maybe, know, action, consequence, anyway...</td>\n",
       "      <td>[0.046260487, 0.04652836, 0.04721831, 0.046761...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>RIC</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>If a man marries a woman then abuses her, and ...</td>\n",
       "      <td>[man, marries, woman, abuse, woman, leave, man...</td>\n",
       "      <td>[0.062142253, 0.062054735, 0.062083445, 0.7516...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>A sin may not be a mistake. As an example, war...</td>\n",
       "      <td>[sin, may, mistake, example, war, depends, the...</td>\n",
       "      <td>[0.051361796, 0.051365696, 0.051335845, 0.7950...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>If a man does wicked things while not being sa...</td>\n",
       "      <td>[man, wicked, thing, sane, also, sin]</td>\n",
       "      <td>[0.059965063, 0.059899706, 0.059892714, 0.7603...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>KSMG</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Is it still a sin if the sinner doesn't know t...</td>\n",
       "      <td>[still, sin, sinner, doesnt, know, sin]</td>\n",
       "      <td>[0.06209156, 0.062614396, 0.06231951, 0.749738...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Yes, perhaps a sin but a forgivable one?</td>\n",
       "      <td>[yes, perhaps, sin, forgivable, one]</td>\n",
       "      <td>[0.06382346, 0.06415827, 0.06461194, 0.0646498...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>I retract my statement. I said that a sin is \"...</td>\n",
       "      <td>[retract, statement, say, sin, forgiveable, me...</td>\n",
       "      <td>[0.050815146, 0.051018137, 0.7958812, 0.051466...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>It depends on one's resolve. Salvation comes f...</td>\n",
       "      <td>[depends, one, resolve, salvation, come, god, ...</td>\n",
       "      <td>[0.04884985, 0.048727453, 0.049004223, 0.80425...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>SAM</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>If I choose to be in hell.</td>\n",
       "      <td>[choose, hell]</td>\n",
       "      <td>[0.66673183, 0.08304718, 0.083804406, 0.083161...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>45</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Begging for forgiveness solves the trick. A mo...</td>\n",
       "      <td>[beg, forgiveness, solves, trick, mortal, sin,...</td>\n",
       "      <td>[0.045594834, 0.8170089, 0.046100833, 0.045766...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>46</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>PY</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>I think there are no sins that are greater or ...</td>\n",
       "      <td>[think, sin, great, lesser, others, sin, lead,...</td>\n",
       "      <td>[0.055921946, 0.05568774, 0.77771324, 0.055463...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>47</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>All sins are forgiveable. But in Catholicism, ...</td>\n",
       "      <td>[sin, forgiveable, catholicism, mortal, sin, u...</td>\n",
       "      <td>[0.04842893, 0.8052829, 0.049018785, 0.0488241...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>48</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>MAR</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>All sin leads to death, and an eternal death i...</td>\n",
       "      <td>[sin, lead, death, eternal, death, state, god,...</td>\n",
       "      <td>[0.051117282, 0.05080512, 0.051612087, 0.79574...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>SAM</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>The sin of rejecting grace. Grace is offered b...</td>\n",
       "      <td>[sin, reject, grace, grace, offer, god, cost, ...</td>\n",
       "      <td>[0.04027155, 0.039686214, 0.03974661, 0.040358...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>50</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>All of us are bound to heaven. Nobody truly re...</td>\n",
       "      <td>[u, bound, heaven, nobody, truly, reject, god,...</td>\n",
       "      <td>[0.77790624, 0.05544274, 0.055525064, 0.055579...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>51</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Salvation is God's decision, but humans contri...</td>\n",
       "      <td>[salvation, god, decision, human, contribute, ...</td>\n",
       "      <td>[0.059046745, 0.05878301, 0.7640284, 0.0591343...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>52</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>ENO</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>God is Holy. Grace makes us live in a holy man...</td>\n",
       "      <td>[god, holy, grace, make, u, live, holy, manner...</td>\n",
       "      <td>[0.041900508, 0.83214974, 0.04185998, 0.041899...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>53</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>KNC</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>But do we have to step in, still? Suicide, for...</td>\n",
       "      <td>[step, still, suicide, example, someone, kill,...</td>\n",
       "      <td>[0.045548722, 0.045727976, 0.04558291, 0.81754...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>54</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>FIN</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>What about those who have heard of Jesus, who ...</td>\n",
       "      <td>[heard, jesus, already, accepted, nonetheless,...</td>\n",
       "      <td>[0.050468, 0.7975348, 0.05048913, 0.051080957,...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>75</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>PY</td>\n",
       "      <td>Do you think yourself sinful?</td>\n",
       "      <td>Yeah, of course. Of course I think I'm a sinn...</td>\n",
       "      <td>[yeah, course, course, think, im, sinner, cour...</td>\n",
       "      <td>[0.82055944, 0.045748297, 0.04452962, 0.044914...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>76</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What sins are unforgivable?</td>\n",
       "      <td>In my opinion, all sins can be forgiven But i...</td>\n",
       "      <td>[opinion, sin, forgiven, catholicism, sin, for...</td>\n",
       "      <td>[0.04242674, 0.043015447, 0.8289378, 0.0432733...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       event_title speaker  \\\n",
       "0   30  Of Sin and Death     KNC   \n",
       "1   31  Of Sin and Death     RIC   \n",
       "2   32  Of Sin and Death     GRE   \n",
       "3   33  Of Sin and Death      PY   \n",
       "4   34  Of Sin and Death     LIV   \n",
       "5   35  Of Sin and Death     TMS   \n",
       "6   36  Of Sin and Death     LIV   \n",
       "7   37  Of Sin and Death     RIC   \n",
       "8   38  Of Sin and Death     GRE   \n",
       "9   39  Of Sin and Death     GRE   \n",
       "10  40  Of Sin and Death    KSMG   \n",
       "11  41  Of Sin and Death     LIV   \n",
       "12  42  Of Sin and Death     LIV   \n",
       "13  43  Of Sin and Death     GRE   \n",
       "14  44  Of Sin and Death     SAM   \n",
       "15  45  Of Sin and Death     GRE   \n",
       "16  46  Of Sin and Death      PY   \n",
       "17  47  Of Sin and Death     LIV   \n",
       "18  48  Of Sin and Death     MAR   \n",
       "19  49  Of Sin and Death     SAM   \n",
       "20  50  Of Sin and Death     LIV   \n",
       "21  51  Of Sin and Death     GRE   \n",
       "22  52  Of Sin and Death     ENO   \n",
       "23  53  Of Sin and Death     KNC   \n",
       "24  54  Of Sin and Death     FIN   \n",
       "25  75  Of Sin and Death      PY   \n",
       "26  76  Of Sin and Death     LIV   \n",
       "\n",
       "                                             question  \\\n",
       "0   What is the difference between a mistake and a...   \n",
       "1   What is the difference between a mistake and a...   \n",
       "2   What is the difference between a mistake and a...   \n",
       "3   What is the difference between a mistake and a...   \n",
       "4   What is the difference between a mistake and a...   \n",
       "5   What is the difference between a mistake and a...   \n",
       "6   What is the difference between a mistake and a...   \n",
       "7   What is the difference between a mistake and a...   \n",
       "8   What is the difference between a mistake and a...   \n",
       "9   What is the difference between a mistake and a...   \n",
       "10  What is the difference between a mistake and a...   \n",
       "11  What is the difference between a mistake and a...   \n",
       "12  What is the difference between a mistake and a...   \n",
       "13  What is the difference between a mistake and a...   \n",
       "14                            What sin leads to hell?   \n",
       "15                            What sin leads to hell?   \n",
       "16                            What sin leads to hell?   \n",
       "17                            What sin leads to hell?   \n",
       "18                            What sin leads to hell?   \n",
       "19                            What sin leads to hell?   \n",
       "20                            What sin leads to hell?   \n",
       "21                            What sin leads to hell?   \n",
       "22                            What sin leads to hell?   \n",
       "23                            What sin leads to hell?   \n",
       "24                            What sin leads to hell?   \n",
       "25                      Do you think yourself sinful?   \n",
       "26                        What sins are unforgivable?   \n",
       "\n",
       "                                               answer  \\\n",
       "0    Yeah, of course. Of course I think I'm a sinn...   \n",
       "1    In my opinion, all sins can be forgiven But i...   \n",
       "2   Human error is a sin. Everything improper is sin.   \n",
       "3   If a man defies a God then he sins. A mistake ...   \n",
       "4     Maybe a sin is a mistake done with evil intent.   \n",
       "5             Sin is commited. Mistake is incidental.   \n",
       "6   Sin is maybe knowing that your actions have co...   \n",
       "7   If a man marries a woman then abuses her, and ...   \n",
       "8   A sin may not be a mistake. As an example, war...   \n",
       "9   If a man does wicked things while not being sa...   \n",
       "10  Is it still a sin if the sinner doesn't know t...   \n",
       "11           Yes, perhaps a sin but a forgivable one?   \n",
       "12  I retract my statement. I said that a sin is \"...   \n",
       "13  It depends on one's resolve. Salvation comes f...   \n",
       "14                         If I choose to be in hell.   \n",
       "15  Begging for forgiveness solves the trick. A mo...   \n",
       "16  I think there are no sins that are greater or ...   \n",
       "17  All sins are forgiveable. But in Catholicism, ...   \n",
       "18  All sin leads to death, and an eternal death i...   \n",
       "19  The sin of rejecting grace. Grace is offered b...   \n",
       "20  All of us are bound to heaven. Nobody truly re...   \n",
       "21  Salvation is God's decision, but humans contri...   \n",
       "22  God is Holy. Grace makes us live in a holy man...   \n",
       "23  But do we have to step in, still? Suicide, for...   \n",
       "24  What about those who have heard of Jesus, who ...   \n",
       "25   Yeah, of course. Of course I think I'm a sinn...   \n",
       "26   In my opinion, all sins can be forgiven But i...   \n",
       "\n",
       "                                            Tokenized  \\\n",
       "0   [yeah, course, course, think, im, sinner, cour...   \n",
       "1   [opinion, sin, forgiven, catholicism, sin, for...   \n",
       "2      [human, error, sin, everything, improper, sin]   \n",
       "3   [man, defies, god, sin, mistake, accident, sin...   \n",
       "4                 [maybe, sin, mistake, evil, intent]   \n",
       "5                  [sin, commit, mistake, incidental]   \n",
       "6   [sin, maybe, know, action, consequence, anyway...   \n",
       "7   [man, marries, woman, abuse, woman, leave, man...   \n",
       "8   [sin, may, mistake, example, war, depends, the...   \n",
       "9               [man, wicked, thing, sane, also, sin]   \n",
       "10            [still, sin, sinner, doesnt, know, sin]   \n",
       "11               [yes, perhaps, sin, forgivable, one]   \n",
       "12  [retract, statement, say, sin, forgiveable, me...   \n",
       "13  [depends, one, resolve, salvation, come, god, ...   \n",
       "14                                     [choose, hell]   \n",
       "15  [beg, forgiveness, solves, trick, mortal, sin,...   \n",
       "16  [think, sin, great, lesser, others, sin, lead,...   \n",
       "17  [sin, forgiveable, catholicism, mortal, sin, u...   \n",
       "18  [sin, lead, death, eternal, death, state, god,...   \n",
       "19  [sin, reject, grace, grace, offer, god, cost, ...   \n",
       "20  [u, bound, heaven, nobody, truly, reject, god,...   \n",
       "21  [salvation, god, decision, human, contribute, ...   \n",
       "22  [god, holy, grace, make, u, live, holy, manner...   \n",
       "23  [step, still, suicide, example, someone, kill,...   \n",
       "24  [heard, jesus, already, accepted, nonetheless,...   \n",
       "25  [yeah, course, course, think, im, sinner, cour...   \n",
       "26  [opinion, sin, forgiven, catholicism, sin, for...   \n",
       "\n",
       "                                       Document Embed  Cluster Assignment  \n",
       "0   [0.82050496, 0.04580212, 0.044529807, 0.044915...                -1.0  \n",
       "1   [0.042426735, 0.043015417, 0.8289398, 0.043271...                -1.0  \n",
       "2   [0.062398467, 0.062497832, 0.7499888, 0.062658...                -1.0  \n",
       "3   [0.7822442, 0.054201584, 0.05532552, 0.0549448...                -1.0  \n",
       "4   [0.06398887, 0.7434575, 0.064547785, 0.0640989...                -1.0  \n",
       "5   [0.06953028, 0.06986823, 0.72250396, 0.0692189...                -1.0  \n",
       "6   [0.046260487, 0.04652836, 0.04721831, 0.046761...                -1.0  \n",
       "7   [0.062142253, 0.062054735, 0.062083445, 0.7516...                -1.0  \n",
       "8   [0.051361796, 0.051365696, 0.051335845, 0.7950...                -1.0  \n",
       "9   [0.059965063, 0.059899706, 0.059892714, 0.7603...                -1.0  \n",
       "10  [0.06209156, 0.062614396, 0.06231951, 0.749738...                -1.0  \n",
       "11  [0.06382346, 0.06415827, 0.06461194, 0.0646498...                -1.0  \n",
       "12  [0.050815146, 0.051018137, 0.7958812, 0.051466...                -1.0  \n",
       "13  [0.04884985, 0.048727453, 0.049004223, 0.80425...                -1.0  \n",
       "14  [0.66673183, 0.08304718, 0.083804406, 0.083161...                -1.0  \n",
       "15  [0.045594834, 0.8170089, 0.046100833, 0.045766...                -1.0  \n",
       "16  [0.055921946, 0.05568774, 0.77771324, 0.055463...                -1.0  \n",
       "17  [0.04842893, 0.8052829, 0.049018785, 0.0488241...                -1.0  \n",
       "18  [0.051117282, 0.05080512, 0.051612087, 0.79574...                -1.0  \n",
       "19  [0.04027155, 0.039686214, 0.03974661, 0.040358...                -1.0  \n",
       "20  [0.77790624, 0.05544274, 0.055525064, 0.055579...                -1.0  \n",
       "21  [0.059046745, 0.05878301, 0.7640284, 0.0591343...                -1.0  \n",
       "22  [0.041900508, 0.83214974, 0.04185998, 0.041899...                -1.0  \n",
       "23  [0.045548722, 0.045727976, 0.04558291, 0.81754...                -1.0  \n",
       "24  [0.050468, 0.7975348, 0.05048913, 0.051080957,...                -1.0  \n",
       "25  [0.82055944, 0.045748297, 0.04452962, 0.044914...                -1.0  \n",
       "26  [0.04242674, 0.043015447, 0.8289378, 0.0432733...                -1.0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.GetAnomalies()\n",
    "ad.df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
