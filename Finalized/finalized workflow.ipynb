{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>IMPORTS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports go here\n",
    "import numpy as np\n",
    "import db\n",
    "import inflect\n",
    "import string\n",
    "import nltk\n",
    "import gensim\n",
    "import contractions\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora, models\n",
    "from nltk.test.gensim_fixt import setup_module\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Init (don't forget to do this when making the class, and only once.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_module()\n",
    "model = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "# see here : https://radimrehurek.com/gensim/downloader.html for saving."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Retrieval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>KSMG</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>I am pro choice. I feel bad for the baby. Peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Logically, both make sense. Conflicted between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JER</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>I'm pro life. Because in my belief, if a fetus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>233</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Prochoice. If she was a victim of rape, etc, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>234</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Prolife for religious reasons. Being religious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>235</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>RIC</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Prochoice. Unless the baby is normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>236</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Legal - not really legal - legal for special c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>237</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Agree with other solutions besides abortion - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>238</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>RIC</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Should be legal with criteria. Agree with Indo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>239</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOR</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>What counts as a person? Is fetus a person?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>240</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Does not being a Christian still fall under Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>241</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>If it has a heartbeat, can it be called life? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>242</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>when something grows doesnt it count as life a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>243</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>KBBI - the process of baby child teenager adul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>244</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>I don't agree with Adam and Eve because not ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>245</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Everyone has rights, even fetuses or babies, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>246</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Is it wrong to regret life? That is the right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>247</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Actually, we humans are well aware that life i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>248</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>The law didn't need to be revised. Choosing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>249</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Rape victims, let's not confuse them, let's di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id         event_title speaker  \\\n",
       "0   230  Of Choice and Life    KSMG   \n",
       "1   231  Of Choice and Life      JJ   \n",
       "2   232  Of Choice and Life     JER   \n",
       "3   233  Of Choice and Life     YOT   \n",
       "4   234  Of Choice and Life     GRE   \n",
       "5   235  Of Choice and Life     RIC   \n",
       "6   236  Of Choice and Life     GRE   \n",
       "7   237  Of Choice and Life     MAR   \n",
       "8   238  Of Choice and Life     RIC   \n",
       "9   239  Of Choice and Life     YOR   \n",
       "10  240  Of Choice and Life     GRE   \n",
       "11  241  Of Choice and Life     YOT   \n",
       "12  242  Of Choice and Life      JJ   \n",
       "13  243  Of Choice and Life     STN   \n",
       "14  244  Of Choice and Life     YOT   \n",
       "15  245  Of Choice and Life     STN   \n",
       "16  246  Of Choice and Life     GRE   \n",
       "17  247  Of Choice and Life     YOT   \n",
       "18  248  Of Choice and Life     STN   \n",
       "19  249  Of Choice and Life     YOT   \n",
       "\n",
       "                                             question  \\\n",
       "0                             Pro life or pro choice?   \n",
       "1                             Pro life or pro choice?   \n",
       "2                             Pro life or pro choice?   \n",
       "3                             Pro life or pro choice?   \n",
       "4                             Pro life or pro choice?   \n",
       "5                             Pro life or pro choice?   \n",
       "6              Do you think abortion should be legal?   \n",
       "7              Do you think abortion should be legal?   \n",
       "8              Do you think abortion should be legal?   \n",
       "9              Do you think abortion should be legal?   \n",
       "10             Do you think abortion should be legal?   \n",
       "11             Do you think abortion should be legal?   \n",
       "12             Do you think abortion should be legal?   \n",
       "13             Do you think abortion should be legal?   \n",
       "14             Do you think abortion should be legal?   \n",
       "15  We see from our side that maybe they are miser...   \n",
       "16  We see from our side that maybe they are miser...   \n",
       "17  We see from our side that maybe they are miser...   \n",
       "18  We see from our side that maybe they are miser...   \n",
       "19  We see from our side that maybe they are miser...   \n",
       "\n",
       "                                               answer  \n",
       "0   I am pro choice. I feel bad for the baby. Peop...  \n",
       "1   Logically, both make sense. Conflicted between...  \n",
       "2   I'm pro life. Because in my belief, if a fetus...  \n",
       "3   Prochoice. If she was a victim of rape, etc, s...  \n",
       "4   Prolife for religious reasons. Being religious...  \n",
       "5               Prochoice. Unless the baby is normal.  \n",
       "6   Legal - not really legal - legal for special c...  \n",
       "7   Agree with other solutions besides abortion - ...  \n",
       "8   Should be legal with criteria. Agree with Indo...  \n",
       "9         What counts as a person? Is fetus a person?  \n",
       "10  Does not being a Christian still fall under Ch...  \n",
       "11  If it has a heartbeat, can it be called life? ...  \n",
       "12  when something grows doesnt it count as life a...  \n",
       "13  KBBI - the process of baby child teenager adul...  \n",
       "14  I don't agree with Adam and Eve because not ev...  \n",
       "15  Everyone has rights, even fetuses or babies, b...  \n",
       "16  Is it wrong to regret life? That is the right ...  \n",
       "17  Actually, we humans are well aware that life i...  \n",
       "18  The law didn't need to be revised. Choosing th...  \n",
       "19  Rape victims, let's not confuse them, let's di...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input : DatabaseHandler\n",
    "# output : DataFrame\n",
    "def GetDF(dh:db.DatabaseHandler, selector: str, eventID: int, splitBySentences: bool = False):\n",
    "    df = dh.get_recordDataJoinedDF(selector=selector, ID=eventID)\n",
    "    if splitBySentences:\n",
    "        # df.set_index('id', inplace=True)\n",
    "        df['answer'] = df['answer'].str.split('.')\n",
    "        df = df.explode(\"answer\", True)\n",
    "        df.drop(df[df[\"answer\"] == \"\"].index, inplace=True)\n",
    "        df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "dh = db.DatabaseHandler(\"testdb.db\")  # db connection\n",
    "df = GetDF(dh, \"event_id\", 20, False)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : sentence/document (string); parameters\n",
    "# output : a list of word tokens (list<string>)\n",
    "def PreprocessDocument(doc:str, isLemma:bool=False, isStopWords:bool=False, isInflect:bool=False, isNumberFiltered:bool=True):\n",
    "    inflector = inflect.engine()\n",
    "    stopwordSet = set(stopwords.words(\"english\"))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    punctuations = string.punctuation\n",
    "    # if numbers are filtered, add that to the punctuation string\n",
    "    if isNumberFiltered:\n",
    "        punctuations += \"1234567890\"\n",
    "\n",
    "    # case fold\n",
    "    doc = doc.lower()\n",
    "\n",
    "    # remove puncs\n",
    "    doc = \"\".join([char for char in doc if char not in punctuations])\n",
    "\n",
    "    # tokenize it.\n",
    "    token_list = nltk.word_tokenize(doc)\n",
    "\n",
    "    for i in range(len(token_list)):\n",
    "        # if inflect\n",
    "        if isInflect:\n",
    "            if token_list[i].isdigit():\n",
    "                token_list[i] = inflector.number_to_words(token_list[i])\n",
    "\n",
    "        # if lemma\n",
    "        if isLemma:\n",
    "            tagged_word = nltk.pos_tag([token_list[i]])\n",
    "            wordnet_pos = getWordnetPos(tagged_word[0][1])\n",
    "            token_list[i] = lemmatizer.lemmatize(tagged_word[0][0], pos=wordnet_pos)\n",
    "        \n",
    "        # if stopword\n",
    "        if isStopWords:\n",
    "            if token_list[i] in stopwordSet or token_list[i].isdigit():\n",
    "                token_list[i] = \"#\" # mark as #\n",
    "        \n",
    "    # remove the marked strings\n",
    "    token_list = [token for token in token_list if token != \"#\"]\n",
    "\n",
    "    if token_list:\n",
    "        return token_list\n",
    "    return [\"\"]\n",
    "\n",
    "def getWordnetPos(tag):\n",
    "    \"\"\"Map POS tag to WordNet POS tag\"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN # solves as noun by default.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['christian', 'still', 'fall', 'christian', 'rule']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySentence = df.loc[10][\"answer\"]\n",
    "myTokenizedSentence = PreprocessDocument(mySentence, isStopWords=True, isLemma=True)\n",
    "myTokenizedSentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get word set, whatever for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "def get_word_set(df):\n",
    "    bigtext = \"\"\n",
    "    # join in lower case\n",
    "    for i in range(len(df)):\n",
    "        bigtext += \" {}\".format(df[i].lower())\n",
    "    bigtext = contractions.fix(bigtext) # remove contractions\n",
    "    bigtext = \"\".join([char for char in bigtext if char not in string.punctuation]) # remove punctuations\n",
    "    big_text_tokens = PreprocessDocument(bigtext, isLemma=True) # put in blender like dick\n",
    "    return set(big_text_tokens) # return as set\n",
    "\n",
    "myWordSet = get_word_set(df[\"answer\"])\n",
    "print(len(myWordSet))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> TF-IDF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : list<str>\n",
    "# output : Dataframe, matrix\n",
    "def GetTFIDF(doclist:list, isPreprocessed=True):\n",
    "    if not isPreprocessed:\n",
    "        doclist = [PreprocessDocument(doc, isLemma=True, isStopWords=True) for doc in doclist]\n",
    "    else:\n",
    "        # just tokenize the thing\n",
    "        doclist = [nltk.word_tokenize(doc) for doc in doclist]\n",
    "        \n",
    "    flat_doclist = [' '.join(doc) for doc in doclist] # turn into one big corpus\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    matrix  = vectorizer.fit_transform(flat_doclist)\n",
    "    tfidf_keys = vectorizer.get_feature_names_out()\n",
    "    df_tfidf = db.pd.DataFrame(matrix.toarray(), columns=tfidf_keys)\n",
    "\n",
    "    return df_tfidf, matrix\n",
    "\n",
    "\n",
    "def GetTFIDF_Gensim(doclist:list, isPreprocessed=True):\n",
    "    if not isPreprocessed:\n",
    "        doclist = [PreprocessDocument(doc, isLemma=True, isStopWords=True, isInflect=True) for doc in doclist]\n",
    "    else:\n",
    "        doclist = [nltk.word_tokenize(doc) for doc in doclist]\n",
    "    dictionary = corpora.Dictionary(doclist)\n",
    "\n",
    "    return dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tfidf, my_matrix = GetTFIDF(df[\"answer\"], isPreprocessed=True)\n",
    "my_tfidf\n",
    "\n",
    "goofy = GetTFIDF_Gensim(df[\"answer\"], False)\n",
    "len(goofy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Word- and Sentence-Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : list<str> : tokens of one document/sentence\n",
    "# output : list<(str, list<int>[300])> : list of word-vector pair for each word available on the model\n",
    "def WordEmbed(document: list, model):\n",
    "    word_embed_pairs = []\n",
    "    for word in document:\n",
    "        if word in model:\n",
    "            word_embed_pairs.append((word, model[word]))\n",
    "    return word_embed_pairs\n",
    "\n",
    "# input : list<(str, list<float>[300])>, str : word-vector pair list and preferred agg method.\n",
    "# output : list<float>[300] : 300-d vector that represents an aggregated value of the input words\n",
    "\n",
    "\n",
    "def SentenceEmbedUnweightedFunction(word_embed_pair_list: list, aggregateMethod: str = \"avg\"):\n",
    "    wvs = []\n",
    "    for pair in word_embed_pair_list:\n",
    "        wvs.append(pair[1])\n",
    "    if aggregateMethod == \"avg\":\n",
    "        return np.mean(wvs, axis=0)\n",
    "    else:\n",
    "        return np.sum(wvs, axis=0)\n",
    "\n",
    "# input : list<list<(str, list<float>[300])>>, str : list containing word-vector pairs and preferred agg method\n",
    "# output : list<(str, list<int>[300])> : list containing sentence-vector pairs.\n",
    "\n",
    "\n",
    "def SentenceEmbedUnweighted(word_embedded_docs: list, aggregateMethod: str = \"avg\"):\n",
    "    sentence_embedded_docs = []\n",
    "    for i in range(len(word_embedded_docs)):\n",
    "        sentence_embedded_docs.append(SentenceEmbedUnweightedFunction(\n",
    "            word_embedded_docs[i], aggregateMethod))\n",
    "    return sentence_embedded_docs\n",
    "\n",
    "\n",
    "'''\n",
    "input :\n",
    "list<list<(str, list<float>[300])>> : word-vector pair list\n",
    "matrix : tf-idf matrix for the corresponding doc\n",
    "int : the row we want\n",
    "str : preferred agg method\n",
    "'''\n",
    "# output : list<float>[300] : 300-d vector that represents an aggregated value of the input words\n",
    "\n",
    "\n",
    "def SentenceEmbedWeightedFunction(word_embed_pair_list: list, tfidf_matrix, index: int, aggregateMethod: str = \"avg\"):\n",
    "    weighted_wvs = []\n",
    "    # multiplies each word with its TF-IDF value in the corresponding row. Is 0 if word isn't found somehow.\n",
    "    for pair in word_embed_pair_list:\n",
    "        tfidf_weight = 0\n",
    "        if pair[0] in tfidf_matrix:\n",
    "            tfidf_weight = tfidf_matrix[pair[0]][index]\n",
    "        weighted_wvs.append(pair[1] * tfidf_weight)\n",
    "    # turn into array for fast aggregating\n",
    "    weighted_wvs = np.array(weighted_wvs)\n",
    "    if aggregateMethod == \"avg\":\n",
    "        sentence_vector = np.mean(weighted_wvs, axis=0)\n",
    "    else:\n",
    "        sentence_vector = np.sum(weighted_wvs, axis=0)\n",
    "    return sentence_vector\n",
    "\n",
    "# input : list<list<(str, list<float>[300])>>, str : list containing word-vector pairs, TF-IDF matrix of the corpus, and preferred agg method\n",
    "# output : list<(str, list<float>[300])> : list containing sentence-vector pairs.\n",
    "\n",
    "\n",
    "def SentenceEmbedWeighted(word_embedded_docs: list, tfidf_matrix, aggregateMethod=\"avg\"):\n",
    "    sentence_embedded_docs = []\n",
    "    for i in range(len(word_embedded_docs)):\n",
    "        sentence_embedded_docs.append(SentenceEmbedWeightedFunction(\n",
    "            word_embedded_docs[i], tfidf_matrix, i, aggregateMethod))\n",
    "    return sentence_embedded_docs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> A list of docs that will be used for everything would still be necessary, after all ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>event_title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Document Embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>KSMG</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>I am pro choice. I feel bad for the baby. Peop...</td>\n",
       "      <td>[-0.022362433, 0.01713121, 0.01336585, -0.0077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Logically, both make sense. Conflicted between...</td>\n",
       "      <td>[-0.007254202, 0.009839708, -0.00799253, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>232</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JER</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>I'm pro life. Because in my belief, if a fetus...</td>\n",
       "      <td>[-0.014276878, 0.0022278614, -0.010473907, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Prochoice. If she was a victim of rape, etc, s...</td>\n",
       "      <td>[-0.022501977, 0.024691759, 0.005002156, 0.017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Prolife for religious reasons. Being religious...</td>\n",
       "      <td>[-0.0040696473, -0.017911343, -0.02254271, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>235</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>RIC</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Prochoice. Unless the baby is normal.</td>\n",
       "      <td>[-0.098942615, 0.024454754, -0.070881665, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>236</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Legal - not really legal - legal for special c...</td>\n",
       "      <td>[0.004587771, -0.0013291183, 0.0049727913, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>237</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Agree with other solutions besides abortion - ...</td>\n",
       "      <td>[-0.01381315, 0.01531402, 0.0022275664, -0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>238</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>RIC</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Should be legal with criteria. Agree with Indo...</td>\n",
       "      <td>[-0.009043147, 0.021918792, -0.030498233, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>239</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOR</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>What counts as a person? Is fetus a person?</td>\n",
       "      <td>[-0.22057891, 0.014038535, -0.20972323, -0.011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>240</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Does not being a Christian still fall under Ch...</td>\n",
       "      <td>[-0.10089697, -0.104009986, -0.051932067, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>241</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>If it has a heartbeat, can it be called life? ...</td>\n",
       "      <td>[0.006337575, 0.01460853, -0.017543007, 0.0111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>242</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>when something grows doesnt it count as life a...</td>\n",
       "      <td>[-0.052422117, 0.030819645, -0.032700323, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>243</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>KBBI - the process of baby child teenager adul...</td>\n",
       "      <td>[0.005943503, 0.010664682, -0.022690445, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>244</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>I don't agree with Adam and Eve because not ev...</td>\n",
       "      <td>[0.016778132, 0.00512473, 0.023938367, -0.0485...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>245</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Everyone has rights, even fetuses or babies, b...</td>\n",
       "      <td>[0.008111107, 0.011857094, 0.019276416, -0.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>246</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Is it wrong to regret life? That is the right ...</td>\n",
       "      <td>[-0.004189881, 0.0068831732, -0.020556947, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>247</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Actually, we humans are well aware that life i...</td>\n",
       "      <td>[-0.0025377192, 7.386828e-05, 0.006843238, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>248</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>The law didn't need to be revised. Choosing th...</td>\n",
       "      <td>[-0.0076232995, 0.0067849657, 0.038440254, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>249</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Rape victims, let's not confuse them, let's di...</td>\n",
       "      <td>[-0.010766402, 0.0011867925, -0.018306145, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   id         event_title speaker  \\\n",
       "0       0  230  Of Choice and Life    KSMG   \n",
       "1       1  231  Of Choice and Life      JJ   \n",
       "2       2  232  Of Choice and Life     JER   \n",
       "3       3  233  Of Choice and Life     YOT   \n",
       "4       4  234  Of Choice and Life     GRE   \n",
       "5       5  235  Of Choice and Life     RIC   \n",
       "6       6  236  Of Choice and Life     GRE   \n",
       "7       7  237  Of Choice and Life     MAR   \n",
       "8       8  238  Of Choice and Life     RIC   \n",
       "9       9  239  Of Choice and Life     YOR   \n",
       "10     10  240  Of Choice and Life     GRE   \n",
       "11     11  241  Of Choice and Life     YOT   \n",
       "12     12  242  Of Choice and Life      JJ   \n",
       "13     13  243  Of Choice and Life     STN   \n",
       "14     14  244  Of Choice and Life     YOT   \n",
       "15     15  245  Of Choice and Life     STN   \n",
       "16     16  246  Of Choice and Life     GRE   \n",
       "17     17  247  Of Choice and Life     YOT   \n",
       "18     18  248  Of Choice and Life     STN   \n",
       "19     19  249  Of Choice and Life     YOT   \n",
       "\n",
       "                                             question  \\\n",
       "0                             Pro life or pro choice?   \n",
       "1                             Pro life or pro choice?   \n",
       "2                             Pro life or pro choice?   \n",
       "3                             Pro life or pro choice?   \n",
       "4                             Pro life or pro choice?   \n",
       "5                             Pro life or pro choice?   \n",
       "6              Do you think abortion should be legal?   \n",
       "7              Do you think abortion should be legal?   \n",
       "8              Do you think abortion should be legal?   \n",
       "9              Do you think abortion should be legal?   \n",
       "10             Do you think abortion should be legal?   \n",
       "11             Do you think abortion should be legal?   \n",
       "12             Do you think abortion should be legal?   \n",
       "13             Do you think abortion should be legal?   \n",
       "14             Do you think abortion should be legal?   \n",
       "15  We see from our side that maybe they are miser...   \n",
       "16  We see from our side that maybe they are miser...   \n",
       "17  We see from our side that maybe they are miser...   \n",
       "18  We see from our side that maybe they are miser...   \n",
       "19  We see from our side that maybe they are miser...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   I am pro choice. I feel bad for the baby. Peop...   \n",
       "1   Logically, both make sense. Conflicted between...   \n",
       "2   I'm pro life. Because in my belief, if a fetus...   \n",
       "3   Prochoice. If she was a victim of rape, etc, s...   \n",
       "4   Prolife for religious reasons. Being religious...   \n",
       "5               Prochoice. Unless the baby is normal.   \n",
       "6   Legal - not really legal - legal for special c...   \n",
       "7   Agree with other solutions besides abortion - ...   \n",
       "8   Should be legal with criteria. Agree with Indo...   \n",
       "9         What counts as a person? Is fetus a person?   \n",
       "10  Does not being a Christian still fall under Ch...   \n",
       "11  If it has a heartbeat, can it be called life? ...   \n",
       "12  when something grows doesnt it count as life a...   \n",
       "13  KBBI - the process of baby child teenager adul...   \n",
       "14  I don't agree with Adam and Eve because not ev...   \n",
       "15  Everyone has rights, even fetuses or babies, b...   \n",
       "16  Is it wrong to regret life? That is the right ...   \n",
       "17  Actually, we humans are well aware that life i...   \n",
       "18  The law didn't need to be revised. Choosing th...   \n",
       "19  Rape victims, let's not confuse them, let's di...   \n",
       "\n",
       "                                       Document Embed  \n",
       "0   [-0.022362433, 0.01713121, 0.01336585, -0.0077...  \n",
       "1   [-0.007254202, 0.009839708, -0.00799253, -0.01...  \n",
       "2   [-0.014276878, 0.0022278614, -0.010473907, 0.0...  \n",
       "3   [-0.022501977, 0.024691759, 0.005002156, 0.017...  \n",
       "4   [-0.0040696473, -0.017911343, -0.02254271, 0.0...  \n",
       "5   [-0.098942615, 0.024454754, -0.070881665, 0.05...  \n",
       "6   [0.004587771, -0.0013291183, 0.0049727913, 0.0...  \n",
       "7   [-0.01381315, 0.01531402, 0.0022275664, -0.004...  \n",
       "8   [-0.009043147, 0.021918792, -0.030498233, -0.0...  \n",
       "9   [-0.22057891, 0.014038535, -0.20972323, -0.011...  \n",
       "10  [-0.10089697, -0.104009986, -0.051932067, 0.09...  \n",
       "11  [0.006337575, 0.01460853, -0.017543007, 0.0111...  \n",
       "12  [-0.052422117, 0.030819645, -0.032700323, -0.0...  \n",
       "13  [0.005943503, 0.010664682, -0.022690445, -0.01...  \n",
       "14  [0.016778132, 0.00512473, 0.023938367, -0.0485...  \n",
       "15  [0.008111107, 0.011857094, 0.019276416, -0.016...  \n",
       "16  [-0.004189881, 0.0068831732, -0.020556947, 0.0...  \n",
       "17  [-0.0025377192, 7.386828e-05, 0.006843238, -0....  \n",
       "18  [-0.0076232995, 0.0067849657, 0.038440254, 0.0...  \n",
       "19  [-0.010766402, 0.0011867925, -0.018306145, -0....  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [PreprocessDocument(doc, isLemma=True, isStopWords=True) for doc in df[\"answer\"]]\n",
    "word_embedded_docs = []\n",
    "for doc in docs:\n",
    "    word_embedded_docs.append(WordEmbed(doc, model))\n",
    "\n",
    "# sentence_embed(\"bababui\", tfidf_matrix=my_tfidf, index=1)\n",
    "doc_embeds = SentenceEmbedWeighted(word_embedded_docs, my_tfidf, \"avg\")\n",
    "df[\"Document Embed\"] = doc_embeds\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True) # don't forget to add this after every row-altering operation.\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>LDA Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015178566, 0.015176928, 0.015178298, 0.01517892, 0.015176928, 0.015178965, 0.015177403, 0.86339366, 0.015181374, 0.015178913]\n",
      "[0.8715595, 0.014267717, 0.014270598, 0.014271023, 0.014267717, 0.0142730465, 0.014269685, 0.014276249, 0.014271883, 0.014272554]\n",
      "[0.011866485, 0.011865227, 0.011866371, 0.011866245, 0.011865227, 0.011867544, 0.011865903, 0.011869738, 0.011866222, 0.8932011]\n",
      "[0.019781291, 0.01978034, 0.821959, 0.019786734, 0.01978034, 0.019783786, 0.019781467, 0.019782048, 0.0197826, 0.019782448]\n",
      "[0.014406338, 0.014404694, 0.014406862, 0.014408974, 0.014404694, 0.01441362, 0.8703269, 0.014411853, 0.014407115, 0.014409003]\n",
      "[0.030097462, 0.03009658, 0.03009934, 0.03010569, 0.03009658, 0.030103652, 0.030097155, 0.030099232, 0.72910494, 0.030099368]\n",
      "[0.015671797, 0.015671214, 0.015672458, 0.015671609, 0.015671214, 0.8589464, 0.015671996, 0.01567902, 0.015671827, 0.015672453]\n",
      "[0.018617284, 0.018616846, 0.01861919, 0.018619861, 0.018616846, 0.01862093, 0.01861727, 0.832436, 0.0186182, 0.018617587]\n",
      "[0.021005102, 0.021004882, 0.021005278, 0.021007098, 0.021004882, 0.02101101, 0.0210055, 0.8109441, 0.021006797, 0.021005388]\n",
      "[0.03092641, 0.03092524, 0.030927047, 0.030925797, 0.03092524, 0.03092602, 0.0309255, 0.7216643, 0.03092624, 0.030928174]\n",
      "[0.027838847, 0.027838647, 0.027838733, 0.027838647, 0.027838647, 0.027838837, 0.027838873, 0.7494513, 0.027838647, 0.02783889]\n",
      "[0.015906438, 0.015904922, 0.015906258, 0.015906079, 0.015904922, 0.015910769, 0.015906626, 0.015907886, 0.8568398, 0.015906291]\n",
      "[0.80662626, 0.021484952, 0.021485008, 0.02148516, 0.021484952, 0.021486562, 0.021485256, 0.02148918, 0.021486238, 0.021486444]\n",
      "[0.012575774, 0.012575189, 0.012578738, 0.012578993, 0.012575189, 0.012580878, 0.012576052, 0.17273933, 0.012580581, 0.7266393]\n",
      "[0.022880103, 0.02288003, 0.02288067, 0.022880796, 0.02288003, 0.022880593, 0.022880632, 0.7940745, 0.02288003, 0.022882586]\n",
      "[0.016989704, 0.016989578, 0.0169908, 0.01699051, 0.016989578, 0.84708554, 0.016989684, 0.016991306, 0.01699314, 0.01699014]\n",
      "[0.016180033, 0.016177343, 0.016180292, 0.01618138, 0.016177343, 0.8543803, 0.016177965, 0.016183859, 0.016179897, 0.016181605]\n",
      "[0.013030089, 0.013026951, 0.8827176, 0.013028377, 0.013026951, 0.013034541, 0.013029281, 0.013044222, 0.013030561, 0.013031416]\n",
      "[0.016423983, 0.01642277, 0.01642425, 0.8521783, 0.01642277, 0.01643073, 0.016423335, 0.016425284, 0.016424347, 0.016424261]\n",
      "[0.011440102, 0.011438417, 0.011446098, 0.89699805, 0.011438417, 0.011444645, 0.011440321, 0.011470491, 0.011440754, 0.01144269]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "input:\n",
    "- doclist : list<list<str>> --> list of tokenized sentences/docs\n",
    "- num_topics : number of inferred topics.\n",
    "'''\n",
    "'''\n",
    "output:\n",
    "- docFeatureList : list<list<float>> --> topic distribution for each sentence/doc\n",
    "'''\n",
    "def GetLDADistribution(doclist: list, topics: int = 5):\n",
    "    new_corpus = []\n",
    "    for i in range(len(docs)):\n",
    "        doc = [(j, my_matrix[i, j]) for j in my_matrix[i].indices]\n",
    "        new_corpus.append(doc)\n",
    "    gensim_dict = corpora.Dictionary.from_corpus(new_corpus)\n",
    "    lda_model = gensim.models.LdaModel(new_corpus, num_topics=10, id2word=gensim_dict)\n",
    "    goofy_ahh_doc_topic_distributions = lda_model[new_corpus]\n",
    "    docFeatureList = []\n",
    "    for doc_topic_dist in goofy_ahh_doc_topic_distributions:\n",
    "        featureList = [0.0 for i in range(0, 10)]\n",
    "        for topic_dist in doc_topic_dist:\n",
    "            featureList[topic_dist[0]] = topic_dist[1]\n",
    "        docFeatureList.append(featureList)\n",
    "    return docFeatureList\n",
    "\n",
    "# myTopicDist = GetLDADistribution(docs, 10)\n",
    "# for topicDist in myTopicDist:\n",
    "#     print(topicDist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Anomaly detection : DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "inputs:\n",
    "- vectors : list<list<float>> --> list of features corresponding to each doc/sentence\n",
    "- epsilon : float --> the radius within which points are considered connected.\n",
    "- min : int --> minimum amount of connected points for a point to be considered a core point of a cluster.\n",
    "'''\n",
    "'''\n",
    "output:\n",
    "clusters : list<int> --> a list of integers to assign each data point to a cluster. -1 means outlier.\n",
    "'''\n",
    "def GetDBSCANClusters(vectors, epsilon:float, min:int):\n",
    "    dbscan = DBSCAN(eps=epsilon, min_samples=min)\n",
    "    clusters = dbscan.fit_predict(vectors)\n",
    "    # plt.title(\"to the depths of depravity {} and the cusp of blasphemy {}.\".format(epsilon, min))\n",
    "    # plt.scatter(vectors[:, 0], vectors[:, 1], c=clusters)\n",
    "    # plt.show()\n",
    "    print(clusters)\n",
    "    return clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  0 -1  0  0  0 -1 -1  0  0  0  0  0  0  0  0  0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0, -1,  0,  0,  0, -1, -1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetDBSCANClusters(list(df[\"Document Embed\"]), 1, 2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Shrink and draw with TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a tsne shrinkage also...\n",
    "def plot_documents(df:db.pd.DataFrame, isPrint=False):\n",
    "    labels = np.arange(0, df.index.stop, 1)\n",
    "    values = list(df[\"Document Embed\"]) # don't forget to list it first, then np array it later.\n",
    "\n",
    "    # train model\n",
    "    tsne_model = TSNE(perplexity=20, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(np.array(values))\n",
    "\n",
    "    # plot\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "    \n",
    "    if isPrint:\n",
    "        plt.figure(figsize=(20, 20)) \n",
    "        for i in range(len(x)):\n",
    "            plt.scatter(x[i],y[i])\n",
    "            plt.annotate(labels[i],\n",
    "                        xy=(x[i], y[i]),\n",
    "                        xytext=(5, 2),\n",
    "                        textcoords='offset points',\n",
    "                        ha='right',\n",
    "                        va='bottom')\n",
    "        plt.show()\n",
    "    # use the thing to find new clusters.\n",
    "    return new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>event_title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Document Embed</th>\n",
       "      <th>Cluster Assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>KSMG</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>I am pro choice. I feel bad for the baby. Peop...</td>\n",
       "      <td>[-0.022362433, 0.01713121, 0.01336585, -0.0077...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Logically, both make sense. Conflicted between...</td>\n",
       "      <td>[-0.007254202, 0.009839708, -0.00799253, -0.01...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>232</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JER</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>I'm pro life. Because in my belief, if a fetus...</td>\n",
       "      <td>[-0.014276878, 0.0022278614, -0.010473907, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Prochoice. If she was a victim of rape, etc, s...</td>\n",
       "      <td>[-0.022501977, 0.024691759, 0.005002156, 0.017...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Pro life or pro choice?</td>\n",
       "      <td>Prolife for religious reasons. Being religious...</td>\n",
       "      <td>[-0.0040696473, -0.017911343, -0.02254271, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>236</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Legal - not really legal - legal for special c...</td>\n",
       "      <td>[0.004587771, -0.0013291183, 0.0049727913, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>237</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Agree with other solutions besides abortion - ...</td>\n",
       "      <td>[-0.01381315, 0.01531402, 0.0022275664, -0.004...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>238</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>RIC</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>Should be legal with criteria. Agree with Indo...</td>\n",
       "      <td>[-0.009043147, 0.021918792, -0.030498233, -0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>241</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>If it has a heartbeat, can it be called life? ...</td>\n",
       "      <td>[0.006337575, 0.01460853, -0.017543007, 0.0111...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>242</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>when something grows doesnt it count as life a...</td>\n",
       "      <td>[-0.052422117, 0.030819645, -0.032700323, -0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>243</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>Do you think abortion should be legal?</td>\n",
       "      <td>KBBI - the process of baby child teenager adul...</td>\n",
       "      <td>[0.005943503, 0.010664682, -0.022690445, -0.01...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>245</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Everyone has rights, even fetuses or babies, b...</td>\n",
       "      <td>[0.008111107, 0.011857094, 0.019276416, -0.016...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>246</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>GRE</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Is it wrong to regret life? That is the right ...</td>\n",
       "      <td>[-0.004189881, 0.0068831732, -0.020556947, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>247</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Actually, we humans are well aware that life i...</td>\n",
       "      <td>[-0.0025377192, 7.386828e-05, 0.006843238, -0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>248</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>STN</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>The law didn't need to be revised. Choosing th...</td>\n",
       "      <td>[-0.0076232995, 0.0067849657, 0.038440254, 0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>249</td>\n",
       "      <td>Of Choice and Life</td>\n",
       "      <td>YOT</td>\n",
       "      <td>We see from our side that maybe they are miser...</td>\n",
       "      <td>Rape victims, let's not confuse them, let's di...</td>\n",
       "      <td>[-0.010766402, 0.0011867925, -0.018306145, -0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index   id         event_title speaker  \\\n",
       "0       0  230  Of Choice and Life    KSMG   \n",
       "1       1  231  Of Choice and Life      JJ   \n",
       "2       2  232  Of Choice and Life     JER   \n",
       "3       3  233  Of Choice and Life     YOT   \n",
       "4       4  234  Of Choice and Life     GRE   \n",
       "6       6  236  Of Choice and Life     GRE   \n",
       "7       7  237  Of Choice and Life     MAR   \n",
       "8       8  238  Of Choice and Life     RIC   \n",
       "11     11  241  Of Choice and Life     YOT   \n",
       "12     12  242  Of Choice and Life      JJ   \n",
       "13     13  243  Of Choice and Life     STN   \n",
       "15     15  245  Of Choice and Life     STN   \n",
       "16     16  246  Of Choice and Life     GRE   \n",
       "17     17  247  Of Choice and Life     YOT   \n",
       "18     18  248  Of Choice and Life     STN   \n",
       "19     19  249  Of Choice and Life     YOT   \n",
       "\n",
       "                                             question  \\\n",
       "0                             Pro life or pro choice?   \n",
       "1                             Pro life or pro choice?   \n",
       "2                             Pro life or pro choice?   \n",
       "3                             Pro life or pro choice?   \n",
       "4                             Pro life or pro choice?   \n",
       "6              Do you think abortion should be legal?   \n",
       "7              Do you think abortion should be legal?   \n",
       "8              Do you think abortion should be legal?   \n",
       "11             Do you think abortion should be legal?   \n",
       "12             Do you think abortion should be legal?   \n",
       "13             Do you think abortion should be legal?   \n",
       "15  We see from our side that maybe they are miser...   \n",
       "16  We see from our side that maybe they are miser...   \n",
       "17  We see from our side that maybe they are miser...   \n",
       "18  We see from our side that maybe they are miser...   \n",
       "19  We see from our side that maybe they are miser...   \n",
       "\n",
       "                                               answer  \\\n",
       "0   I am pro choice. I feel bad for the baby. Peop...   \n",
       "1   Logically, both make sense. Conflicted between...   \n",
       "2   I'm pro life. Because in my belief, if a fetus...   \n",
       "3   Prochoice. If she was a victim of rape, etc, s...   \n",
       "4   Prolife for religious reasons. Being religious...   \n",
       "6   Legal - not really legal - legal for special c...   \n",
       "7   Agree with other solutions besides abortion - ...   \n",
       "8   Should be legal with criteria. Agree with Indo...   \n",
       "11  If it has a heartbeat, can it be called life? ...   \n",
       "12  when something grows doesnt it count as life a...   \n",
       "13  KBBI - the process of baby child teenager adul...   \n",
       "15  Everyone has rights, even fetuses or babies, b...   \n",
       "16  Is it wrong to regret life? That is the right ...   \n",
       "17  Actually, we humans are well aware that life i...   \n",
       "18  The law didn't need to be revised. Choosing th...   \n",
       "19  Rape victims, let's not confuse them, let's di...   \n",
       "\n",
       "                                       Document Embed  Cluster Assignment  \n",
       "0   [-0.022362433, 0.01713121, 0.01336585, -0.0077...                   0  \n",
       "1   [-0.007254202, 0.009839708, -0.00799253, -0.01...                   0  \n",
       "2   [-0.014276878, 0.0022278614, -0.010473907, 0.0...                   0  \n",
       "3   [-0.022501977, 0.024691759, 0.005002156, 0.017...                   0  \n",
       "4   [-0.0040696473, -0.017911343, -0.02254271, 0.0...                   0  \n",
       "6   [0.004587771, -0.0013291183, 0.0049727913, 0.0...                   0  \n",
       "7   [-0.01381315, 0.01531402, 0.0022275664, -0.004...                   0  \n",
       "8   [-0.009043147, 0.021918792, -0.030498233, -0.0...                   0  \n",
       "11  [0.006337575, 0.01460853, -0.017543007, 0.0111...                   0  \n",
       "12  [-0.052422117, 0.030819645, -0.032700323, -0.0...                   0  \n",
       "13  [0.005943503, 0.010664682, -0.022690445, -0.01...                   0  \n",
       "15  [0.008111107, 0.011857094, 0.019276416, -0.016...                   0  \n",
       "16  [-0.004189881, 0.0068831732, -0.020556947, 0.0...                   0  \n",
       "17  [-0.0025377192, 7.386828e-05, 0.006843238, -0....                   0  \n",
       "18  [-0.0076232995, 0.0067849657, 0.038440254, 0.0...                   0  \n",
       "19  [-0.010766402, 0.0011867925, -0.018306145, -0....                   0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clusters = GetDBSCANClusters(list(df[\"Document Embed\"]), 0.6, 5)\n",
    "# df[\"Cluster Assignment\"] = clusters\n",
    "# dfSupposedOutliers = df.loc[df[\"Cluster Assignment\"] == -1]\n",
    "# dfSupposedGoods = df.loc[df[\"Cluster Assignment\"] != -1]\n",
    "# dfSupposedGoods.reset_index(inplace=True)\n",
    "# dfSupposedOutliers.reset_index(inplace=True)\n",
    "\n",
    "# for i in range(len(dfSupposedOutliers.index)):\n",
    "#     print(dfSupposedOutliers.loc[i][\"question\"], \" | \", dfSupposedOutliers.loc[i][\"answer\"])\n",
    "\n",
    "# print(\"#\" * 80)\n",
    "# for i in range(len(dfSupposedGoods.index)):\n",
    "#     print(dfSupposedGoods.loc[i][\"question\"], \" | \", dfSupposedGoods.loc[i][\"answer\"])\n",
    "\n",
    "'''\n",
    "inputs :\n",
    "- clusters : list<int> --> a list of clusters assigned to each doc/sentence\n",
    "- df : DataFrame --> the dataframe in question\n",
    "'''\n",
    "'''\n",
    "outputs:\n",
    "- dfOutliers : DataFrame --> the dataframe whose answers have been marked as outliers.\n",
    "- dfGoods : DataFrame --> the dataframe whose answers have not been marked as outliers.\n",
    "'''\n",
    "def ReturnClusters(clusters:list, df:db.pd.DataFrame):\n",
    "    df[\"Cluster Assignment\"] = clusters\n",
    "    dfGoods = df.loc[df[\"Cluster Assignment\"] != -1]\n",
    "    dfOutliers = df.loc[df[\"Cluster Assignment\"] == -1]\n",
    "    return dfOutliers, dfGoods\n",
    "\n",
    "# outliers, goods = ReturnClusters(clusters, df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Anomaly detection : LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetLDADistribution(doclist: list, topics: int = 5, use_tfidf: bool = True):\n",
    "    new_corpus = []\n",
    "    \n",
    "    if use_tfidf:\n",
    "        for i in range(len(doclist)):\n",
    "            doc = [(j, my_matrix[i, j]) for j in my_matrix[i].indices]\n",
    "            new_corpus.append(doc)\n",
    "            gensim_dict = corpora.Dictionary.from_corpus(new_corpus)        \n",
    "    else:\n",
    "        gensim_dict = corpora.Dictionary(doclist)\n",
    "        new_corpus = [gensim_dict.doc2bow(doc) for doc in doclist]\n",
    "        \n",
    "    lda_model = gensim.models.LdaModel(new_corpus, num_topics=topics, id2word=gensim_dict)\n",
    "    goofy_ahh_doc_topic_distributions = lda_model[new_corpus]\n",
    "    \n",
    "    docFeatureList = []\n",
    "    for doc_topic_dist in goofy_ahh_doc_topic_distributions:\n",
    "        featureList = [0.0 for i in range(0, topics)]\n",
    "        for topic_dist in doc_topic_dist:\n",
    "            featureList[topic_dist[0]] = topic_dist[1]\n",
    "        docFeatureList.append(featureList)\n",
    "    \n",
    "    return docFeatureList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9594759, 0.040524174]\n",
      "[0.97850245, 0.021497536]\n",
      "[0.28016606, 0.7198339]\n",
      "[0.043442782, 0.9565572]\n",
      "[0.9731329, 0.026867067]\n",
      "[0.82650346, 0.17349651]\n",
      "[0.023954507, 0.9760455]\n",
      "[0.92979133, 0.07020863]\n",
      "[0.34196287, 0.6580371]\n",
      "[0.123561874, 0.87643814]\n",
      "[0.09156124, 0.90843874]\n",
      "[0.030009115, 0.9699909]\n",
      "[0.052324902, 0.94767505]\n",
      "[0.015818512, 0.98418146]\n",
      "[0.906932, 0.09306796]\n",
      "[0.03421068, 0.96578926]\n",
      "[0.02900701, 0.970993]\n",
      "[0.018301684, 0.98169833]\n",
      "[0.97891814, 0.021081883]\n",
      "[0.9852539, 0.014746079]\n"
     ]
    }
   ],
   "source": [
    "thing = GetLDADistribution(docs, 2, False)\n",
    "for item in thing:\n",
    "    print(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Anomaly detection : Isolation Forest (sklearn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Final Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector():\n",
    "    def __init__(self, dbName: str = \"\",  dh=None, model=None) -> None:\n",
    "        if dh is None:\n",
    "            self.dh = db.DatabaseHandler(dbName=dbName)\n",
    "        else:\n",
    "            self.dh = dh\n",
    "        if model is None:\n",
    "            self.model = api.load(\"glove-wiki-gigaword-300\")\n",
    "        else:\n",
    "            self.model = model\n",
    "    # def __init__(self, eventID: int, isSplit: bool) -> None:\n",
    "    #     self.dh = db.DatabaseHandler(\"test.db\")\n",
    "    #     self.df = self.GetDF(self.dh, \"eventID\", eventID, isSplit)\n",
    "    #     self.model = api.load(\"glove-wiki-gigaword-300\")\n",
    "    #     pass\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - dh : DatabaseHandler --> to retrieve data from database\n",
    "    - eventID : int --> we're doing this by event, so straight to the eventID\n",
    "    - selector : str --> pretty much formality.\n",
    "    - splitBySentences : bool --> Split each doc into sentences or not. Defaults to no.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    None, just setting\n",
    "    '''\n",
    "\n",
    "    def SetDF(self, dh: db.DatabaseHandler, eventID: int, selector: str = \"event_id\", splitBySentences: bool = False):\n",
    "        self.df = self.dh.get_recordDataJoinedDF(selector=selector, ID=eventID)\n",
    "        if splitBySentences:\n",
    "            # df.set_index('id', inplace=True)\n",
    "            self.df['answer'] = self.df['answer'].str.split('.')\n",
    "            self.df = self.df.explode(\"answer\", True)\n",
    "            self.df.drop(self.df[self.df[\"answer\"] == \"\"].index, inplace=True)\n",
    "            self.df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - dh : DatabaseHandler --> to retrieve data from database\n",
    "    - eventID : int --> we're doing this by event, so straight to the eventID\n",
    "    - selector : str --> pretty much formality.\n",
    "    - splitBySentences : bool --> Split each doc into sentences or not. Defaults to no.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - df : DataFrame --> dataframe containing the thing we're gonna be using.\n",
    "    '''\n",
    "\n",
    "    def GetDF(self, dh: db.DatabaseHandler, eventID: int, selector: str = \"event_id\", splitBySentences: bool = False):\n",
    "        df = dh.get_recordDataJoinedDF(selector=selector, ID=eventID)\n",
    "        if splitBySentences:\n",
    "            # df.set_index('id', inplace=True)\n",
    "            df['answer'] = df['answer'].str.split('.')\n",
    "            df = df.explode(\"answer\", True)\n",
    "            df.drop(df[df[\"answer\"] == \"\"].index, inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - doc : str --> a string representing a sentence/document.\n",
    "    - isLemma : bool --> use lemmatizer or not? Defaults to not.\n",
    "    - isStopWords : bool --> use stopwords or not? Defaults to not.\n",
    "    - isInflect : bool --> use inflections (you're --> you are) or not? Defaults to not.\n",
    "    - isNumberFiltered :  bool --> delete numbers in the string? Defaults to yes. \n",
    "    '''\n",
    "    '''\n",
    "    output : list<str> --> a list of word tokens (list<string>)\n",
    "    '''\n",
    "\n",
    "    def PreprocessDocument(self, doc: str, isLemma: bool = False, isStopWords: bool = False, isInflect: bool = False, isNumberFiltered: bool = True):\n",
    "        inflector = inflect.engine()\n",
    "        stopwordSet = set(stopwords.words(\"english\"))\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        punctuations = string.punctuation\n",
    "        # if numbers are filtered, add that to the punctuation string\n",
    "        if isNumberFiltered:\n",
    "            punctuations += \"1234567890\"\n",
    "\n",
    "        # case fold\n",
    "        doc = doc.lower()\n",
    "\n",
    "        # remove puncs\n",
    "        doc = \"\".join([char for char in doc if char not in punctuations])\n",
    "\n",
    "        # tokenize it.\n",
    "        token_list = nltk.word_tokenize(doc)\n",
    "\n",
    "        for i in range(len(token_list)):\n",
    "            # if inflect\n",
    "            if isInflect:\n",
    "                if token_list[i].isdigit():\n",
    "                    token_list[i] = inflector.number_to_words(token_list[i])\n",
    "\n",
    "            # if lemma\n",
    "            if isLemma:\n",
    "                tagged_word = nltk.pos_tag([token_list[i]])\n",
    "                wordnet_pos = getWordnetPos(tagged_word[0][1])\n",
    "                token_list[i] = lemmatizer.lemmatize(\n",
    "                    tagged_word[0][0], pos=wordnet_pos)\n",
    "\n",
    "            # if stopword\n",
    "            if isStopWords:\n",
    "                if token_list[i] in stopwordSet or token_list[i].isdigit():\n",
    "                    token_list[i] = \"#\"  # mark as #\n",
    "\n",
    "        # remove the marked strings\n",
    "        token_list = [token for token in token_list if token != \"#\"]\n",
    "\n",
    "        if token_list:\n",
    "            return token_list\n",
    "        return [\"\"]\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - tag : str --> the tag obtained from POS tagging.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - str --> Wordnet POS tag.\n",
    "    '''\n",
    "    def getWordnetPos(tag):\n",
    "        \"\"\"Map POS tag to WordNet POS tag\"\"\"\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN  # solves as noun by default.\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - doclist : list<str> --> list of doc/sentences.\n",
    "    - isProcessed : bool --> has it already been preprocessed? Defaults to True.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - df_tfidf : Dataframe --> the TFIDF matrix in df form. \n",
    "    - matrix : matrix --> the TFIDF matrix purely. mainly for LDA purposes.\n",
    "    '''\n",
    "\n",
    "    def GetTFIDF(self, doclist: list, isPreprocessed=True):\n",
    "        if not isPreprocessed:\n",
    "            doclist = [PreprocessDocument(\n",
    "                doc, isLemma=True, isStopWords=True) for doc in doclist]\n",
    "        # else:\n",
    "        #     # just tokenize the thing\n",
    "        #     doclist = [nltk.word_tokenize(doc) for doc in doclist]\n",
    "        # i think the thing has already been tokenized. That's the problem.\n",
    "        flat_doclist = [' '.join(doc)\n",
    "                        for doc in doclist]  # turn into one big corpus\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        matrix = vectorizer.fit_transform(flat_doclist)\n",
    "        tfidf_keys = vectorizer.get_feature_names_out()\n",
    "        df_tfidf = db.pd.DataFrame(matrix.toarray(), columns=tfidf_keys)\n",
    "\n",
    "        return df_tfidf, matrix\n",
    "\n",
    "    # input : list<str> : tokens of one document/sentence\n",
    "    # output : list<(str, list<int>[300])> : list of word-vector pair for each word available on the model\n",
    "    def WordEmbed(self, document: list, model):\n",
    "        word_embed_pairs = []\n",
    "        for word in document:\n",
    "            if word in model:\n",
    "                word_embed_pairs.append((word, model[word]))\n",
    "        return word_embed_pairs\n",
    "\n",
    "    # input : list<(str, list<float>[300])>, str : word-vector pair list and preferred agg method.\n",
    "    # output : list<float>[300] : 300-d vector that represents an aggregated value of the input words\n",
    "    def SentenceEmbedUnweightedFunction(self, word_embed_pair_list: list, aggregateMethod: str = \"avg\"):\n",
    "        wvs = []\n",
    "        for pair in word_embed_pair_list:\n",
    "            wvs.append(pair[1])\n",
    "        if aggregateMethod == \"avg\":\n",
    "            return np.mean(wvs, axis=0)\n",
    "        else:\n",
    "            return np.sum(wvs, axis=0)\n",
    "\n",
    "    # input : list<list<(str, list<float>[300])>>, str : list containing word-vector pairs and preferred agg method\n",
    "    # output : list<(str, list<int>[300])> : list containing sentence-vector pairs.\n",
    "    def SentenceEmbedUnweighted(self, word_embedded_docs: list, aggregateMethod: str = \"avg\"):\n",
    "        sentence_embedded_docs = []\n",
    "        for i in range(len(word_embedded_docs)):\n",
    "            sentence_embedded_docs.append(SentenceEmbedUnweightedFunction(\n",
    "                word_embedded_docs[i], aggregateMethod))\n",
    "        return sentence_embedded_docs\n",
    "\n",
    "    '''\n",
    "    input :\n",
    "    list<list<(str, list<float>[300])>> : word-vector pair list\n",
    "    matrix : tf-idf matrix for the corresponding doc\n",
    "    int : the row we want\n",
    "    str : preferred agg method\n",
    "    '''\n",
    "    # output : list<float>[300] : 300-d vector that represents an aggregated value of the input words\n",
    "\n",
    "    def SentenceEmbedWeightedFunction(self, word_embed_pair_list: list, tfidf_matrix, index: int, aggregateMethod: str = \"avg\"):\n",
    "        weighted_wvs = []\n",
    "        # multiplies each word with its TF-IDF value in the corresponding row. Is 0 if word isn't found somehow.\n",
    "        for pair in word_embed_pair_list:\n",
    "            tfidf_weight = 0\n",
    "            if pair[0] in tfidf_matrix:\n",
    "                tfidf_weight = tfidf_matrix[pair[0]][index]\n",
    "            weighted_wvs.append(pair[1] * tfidf_weight)\n",
    "        # turn into array for fast aggregating\n",
    "        weighted_wvs = np.array(weighted_wvs)\n",
    "        if aggregateMethod == \"avg\":\n",
    "            sentence_vector = np.mean(weighted_wvs, axis=0)\n",
    "        else:\n",
    "            sentence_vector = np.sum(weighted_wvs, axis=0)\n",
    "        return sentence_vector\n",
    "\n",
    "    # input : list<list<(str, list<float>[300])>>, str : list containing word-vector pairs, TF-IDF matrix of the corpus, and preferred agg method\n",
    "    # output : list<(str, list<float>[300])> : list containing sentence-vector pairs.\n",
    "    def SentenceEmbedWeighted(self, word_embedded_docs: list, tfidf_matrix, aggregateMethod=\"avg\"):\n",
    "        sentence_embedded_docs = []\n",
    "        for i in range(len(word_embedded_docs)):\n",
    "            sentence_embedded_docs.append(SentenceEmbedWeightedFunction(\n",
    "                word_embedded_docs[i], tfidf_matrix, i, aggregateMethod))\n",
    "        return sentence_embedded_docs\n",
    "\n",
    "    '''\n",
    "    input:\n",
    "    - doclist : list<list<str>> --> list of tokenized sentences/docs\n",
    "    - topics : int --> number of inferred topics.\n",
    "    - use_tfidf : bool --> use TFIDF or not? defaults to yes.\n",
    "    '''\n",
    "    '''\n",
    "    output:\n",
    "    - docFeatureList : list<list<float>> --> topic distribution for each sentence/doc\n",
    "    '''\n",
    "\n",
    "    def GetLDADistribution(self, doclist: list, topics: int = 5, use_tfidf: bool = True):\n",
    "        new_corpus = []\n",
    "        \n",
    "        if use_tfidf:\n",
    "            for i in range(len(doclist)):\n",
    "                doc = [(j, self.tfidf_matrix[i, j]) for j in self.tfidf_matrix[i].indices]\n",
    "                new_corpus.append(doc)\n",
    "                gensim_dict = corpora.Dictionary.from_corpus(new_corpus)        \n",
    "        else:\n",
    "            gensim_dict = corpora.Dictionary(doclist)\n",
    "            new_corpus = [gensim_dict.doc2bow(doc) for doc in doclist]\n",
    "            \n",
    "        lda_model = gensim.models.LdaModel(new_corpus, num_topics=topics, id2word=gensim_dict)\n",
    "        goofy_ahh_doc_topic_distributions = lda_model[new_corpus]\n",
    "        \n",
    "        docFeatureList = []\n",
    "        for doc_topic_dist in goofy_ahh_doc_topic_distributions:\n",
    "            featureList = [0.0 for i in range(0, topics)]\n",
    "            for topic_dist in doc_topic_dist:\n",
    "                featureList[topic_dist[0]] = topic_dist[1]\n",
    "            docFeatureList.append(featureList)\n",
    "        \n",
    "        return docFeatureList\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - vectors : list<list<float>> --> list of features corresponding to each doc/sentence\n",
    "    - epsilon : float --> the radius within which points are considered connected.\n",
    "    - min : int --> minimum amount of connected points for a point to be considered a core point of a cluster.\n",
    "    '''\n",
    "    '''\n",
    "    output:\n",
    "    clusters : list<int> --> a list of integers to assign each data point to a cluster. -1 means outlier.\n",
    "    '''\n",
    "\n",
    "    def GetDBSCANClusters(self, vectors, epsilon: float, min: int):\n",
    "        dbscan = DBSCAN(eps=epsilon, min_samples=min)\n",
    "        clusters = dbscan.fit_predict(vectors)\n",
    "        # plt.title(\"to the depths of depravity {} and the cusp of blasphemy {}.\".format(epsilon, min))\n",
    "        # plt.scatter(vectors[:, 0], vectors[:, 1], c=clusters)\n",
    "        # plt.show()\n",
    "        # print(clusters)\n",
    "        return clusters\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - clusters : list<int> --> a list of clusters assigned to each doc/sentence\n",
    "    - df : DataFrame --> the dataframe in question\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - dfOutliers : DataFrame --> the dataframe whose answers have been marked as outliers.\n",
    "    - dfGoods : DataFrame --> the dataframe whose answers have not been marked as outliers.\n",
    "    '''\n",
    "\n",
    "    def ReturnClusters(self, clusters: list, df: db.pd.DataFrame):\n",
    "        df[\"Cluster Assignment\"] = clusters\n",
    "        dfGoods = df.loc[df[\"Cluster Assignment\"] != -1]\n",
    "        dfOutliers = df.loc[df[\"Cluster Assignment\"] == -1]\n",
    "        return dfOutliers, dfGoods\n",
    "\n",
    "    def GetAnomalies_DBSCAN_Embedding(self, isWeighted: bool = True, aggregateMethod: str = \"avg\", epsilon: float = 0.01, minsamp: int = 2):\n",
    "        # df and model are obtained by invoking a separate function, and it is assumed to be already available when invoking this function.\n",
    "\n",
    "        # preprocess each doc/sentence\n",
    "        self.preprocessedDocs = [self.PreprocessDocument(\n",
    "            doc, isLemma=True, isStopWords=True) for doc in self.df[\"answer\"]]\n",
    "\n",
    "        # extract feature with embedding\n",
    "        self.wordEmbeddedDocs = [self.WordEmbed(\n",
    "            doc, self.model) for doc in self.preprocessedDocs]\n",
    "\n",
    "        # if weighted, prepare TF-IDF and embed sentences with weight.\n",
    "        if isWeighted:\n",
    "            self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                self.preprocessedDocs)\n",
    "            self.doc_embeds = self.SentenceEmbedWeighted(\n",
    "                self.wordEmbeddedDocs, self.tfidf_df, aggregateMethod)\n",
    "        else:\n",
    "            self.doc_embeds = self.SentenceEmbedUnweighted(\n",
    "                self.wordEmbeddedDocs, aggregateMethod)\n",
    "\n",
    "        # append embedding to each document\n",
    "        if self.doc_embeds:\n",
    "            self.df[\"Document Embed\"] = self.doc_embeds\n",
    "\n",
    "        # apply DBSCAN\n",
    "        self.clusters = self.GetDBSCANClusters(\n",
    "            list(self.df[\"Document Embed\"]), epsilon, minsamp)\n",
    "\n",
    "        # return the dfs\n",
    "        return self.ReturnClusters(self.clusters, self.df)\n",
    "\n",
    "    def GetAnomalies_DBSCAN_LDA(self, isWeighted: bool = True, topics: int = 5, epsilon: float = 0.01, minsamp: int = 5):\n",
    "        # df and model are obtained by invoking a separate function, and it is assumed to be already available when invoking this function.\n",
    "\n",
    "        # preprocess each doc/sentence\n",
    "        self.preprocessedDocs = [self.PreprocessDocument(\n",
    "            doc, isLemma=True, isStopWords=True) for doc in self.df[\"answer\"]]\n",
    "\n",
    "        # extract feature with embedding\n",
    "        self.wordEmbeddedDocs = [self.WordEmbed(\n",
    "            doc, self.model) for doc in self.preprocessedDocs]\n",
    "\n",
    "        # if weighted, prepare tf-idf matrix.\n",
    "        if isWeighted:\n",
    "            self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                self.preprocessedDocs)\n",
    "        \n",
    "        # use the in-house options for weighted or not.\n",
    "        self.doc_embeds = self.GetLDADistribution(\n",
    "            self.preprocessedDocs, topics=topics, use_tfidf=isWeighted)\n",
    "\n",
    "        # append embedding to each document\n",
    "        if self.doc_embeds:\n",
    "            self.df[\"Document Embed\"] = self.doc_embeds\n",
    "\n",
    "        # apply DBSCAN\n",
    "        self.clusters = self.GetDBSCANClusters(\n",
    "            list(self.df[\"Document Embed\"]), epsilon, minsamp)\n",
    "\n",
    "        # return the dfs\n",
    "        return self.ReturnClusters(self.clusters, self.df)\n",
    "\n",
    "    def GetAnomalies(self, method: str, model, isWeighted: bool = True, aggregateMethod: str = \"avg\", epsilon=0.01, minsamp=2, topics=5):\n",
    "        # initialize\n",
    "        # extract the dataset\n",
    "        self.df = self.GetDF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "goofyDH = ad.dh\n",
    "goofyModel = ad.model\n",
    "\n",
    "ad = AnomalyDetector(dh=goofyDH, model=goofyModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.SetDF(ad.dh, 19, \"event_id\", splitBySentences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "myOutliers, myGoods = ad.GetAnomalies_DBSCAN_LDA(False, topics=5, epsilon=0.6, minsamp=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Document Embed</th>\n",
       "      <th>Cluster Assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>KNC</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>A mistake isn't necessarily evil</td>\n",
       "      <td>[0.040007103, 0.040260684, 0.5996429, 0.040007...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>KNC</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>A sin is surely evil</td>\n",
       "      <td>[0.050733026, 0.05167625, 0.050830543, 0.05037...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>RIC</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>A sin is wicked in the eyes of god</td>\n",
       "      <td>[0.04065759, 0.04073258, 0.83709264, 0.0403079...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>RIC</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>A mistake isn't always wicked in the eyes of God</td>\n",
       "      <td>[0.02875328, 0.028849144, 0.029649774, 0.02880...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>207</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Human error is a sin</td>\n",
       "      <td>[0.051153332, 0.05164998, 0.051087644, 0.05037...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>207</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Everything improper is sin</td>\n",
       "      <td>[0.050962675, 0.052271932, 0.050853908, 0.7952...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>208</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>PY</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>If a man defies a God then he sins</td>\n",
       "      <td>[0.04075263, 0.041490786, 0.0412334, 0.835983,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>208</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>PY</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>A mistake can be done by accident, but a sin ...</td>\n",
       "      <td>[0.033426974, 0.8655161, 0.033683017, 0.033384...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>209</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Maybe a sin is a mistake done with evil intent</td>\n",
       "      <td>[0.033608258, 0.034077697, 0.033972435, 0.0334...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>210</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>TMS</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Sin is commited</td>\n",
       "      <td>[0.06717221, 0.73141354, 0.06747436, 0.0669311...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>210</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>TMS</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Mistake is incidental</td>\n",
       "      <td>[0.06667743, 0.06764174, 0.7308169, 0.06667845...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>211</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Sin is maybe knowing that your actions have co...</td>\n",
       "      <td>[0.029023949, 0.02901999, 0.8844514, 0.0286515...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>211</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>What then about a child that doesn't know any...</td>\n",
       "      <td>[0.89954734, 0.02514468, 0.025158007, 0.025005...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>212</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>RIC</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>If a man marries a woman then abuses her, and ...</td>\n",
       "      <td>[0.018299364, 0.018419018, 0.018264854, 0.9267...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>213</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>A sin may not be a mistake</td>\n",
       "      <td>[0.05024181, 0.7978977, 0.05078991, 0.05012995...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>213</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>As an example, war</td>\n",
       "      <td>[0.06668108, 0.06762332, 0.0666819, 0.73088604...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>213</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>It depends on which theology to decide whethe...</td>\n",
       "      <td>[0.028575059, 0.028575044, 0.02857535, 0.02867...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>214</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>If a man does wicked things while not being sa...</td>\n",
       "      <td>[0.8840682, 0.028986592, 0.028839175, 0.029245...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>215</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>KSMG</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Is it still a sin if the sinner doesn't know t...</td>\n",
       "      <td>[0.029255424, 0.8843754, 0.029063754, 0.028642...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>216</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Yes, perhaps a sin but a forgivable one?</td>\n",
       "      <td>[0.86566013, 0.033727832, 0.033502348, 0.03352...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>217</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>I retract my statement</td>\n",
       "      <td>[0.06668017, 0.066680245, 0.06668144, 0.733272...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>217</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>I said that a sin is \"forgiveable\", but I mea...</td>\n",
       "      <td>[0.9269299, 0.01836987, 0.018226681, 0.0182565...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>218</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>It depends on one's resolve</td>\n",
       "      <td>[0.050820436, 0.050006114, 0.050006703, 0.0503...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>218</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What is the difference between a mistake and a...</td>\n",
       "      <td>Salvation comes from God and nary a man's act...</td>\n",
       "      <td>[0.025198245, 0.8981943, 0.02571765, 0.0257437...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>219</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>SAM</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>If I choose to be in hell</td>\n",
       "      <td>[0.06741853, 0.06741675, 0.06667862, 0.0666788...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>220</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Begging for forgiveness solves the trick</td>\n",
       "      <td>[0.04000567, 0.040005684, 0.040006224, 0.04000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>220</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>A mortal sin committed continuously, or a sin...</td>\n",
       "      <td>[0.025097737, 0.89940095, 0.025380086, 0.02505...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>220</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Some sins are harder to forgive than others</td>\n",
       "      <td>[0.04032007, 0.041135516, 0.8381561, 0.0401693...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>221</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>PY</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>I think there are no sins that are greater or ...</td>\n",
       "      <td>[0.022592979, 0.91038305, 0.022374373, 0.02226...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>222</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>All sins are forgiveable</td>\n",
       "      <td>[0.06842044, 0.73050046, 0.06712451, 0.0669376...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>222</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>But in Catholicism, there are mortal sins tha...</td>\n",
       "      <td>[0.040143333, 0.8395497, 0.04012863, 0.0400778...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>222</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>These are sins that are very grave, such that...</td>\n",
       "      <td>[0.0287198, 0.028934887, 0.8850192, 0.02865149...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>223</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>MAR</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>All sin leads to death, and an eternal death i...</td>\n",
       "      <td>[0.89840376, 0.025333278, 0.025686143, 0.02536...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>223</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>MAR</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Even a trivial transgression or imperfection ...</td>\n",
       "      <td>[0.8856597, 0.028610762, 0.028576, 0.028576126...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>223</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>MAR</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>It does not matter what your sin is; if you h...</td>\n",
       "      <td>[0.86474687, 0.03445685, 0.033673394, 0.033532...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>224</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>SAM</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>The sin of rejecting grace</td>\n",
       "      <td>[0.05055334, 0.05118644, 0.7952202, 0.05266554...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>224</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>SAM</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Grace is offered by God, costing nothing, to ...</td>\n",
       "      <td>[0.025127135, 0.025073422, 0.025245171, 0.8994...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>224</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>SAM</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>To know that it is offered to us with no char...</td>\n",
       "      <td>[0.9381442, 0.0154988635, 0.015440245, 0.01545...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>225</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>All of us are bound to heaven</td>\n",
       "      <td>[0.05189561, 0.7975153, 0.050011735, 0.0505620...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>225</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>LIV</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Nobody truly rejects God voluntarily</td>\n",
       "      <td>[0.033370886, 0.033371, 0.8664448, 0.0334253, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>226</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>GRE</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Salvation is God's decision, but humans contri...</td>\n",
       "      <td>[0.028716832, 0.028717935, 0.8851434, 0.028637...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>227</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>ENO</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>God is Holy</td>\n",
       "      <td>[0.06685794, 0.06685859, 0.73089373, 0.0684427...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>227</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>ENO</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>Grace makes us live in a holy manner</td>\n",
       "      <td>[0.028849918, 0.028688926, 0.028736042, 0.8851...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>227</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>ENO</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>There is no special treatment to eternal life...</td>\n",
       "      <td>[0.020260472, 0.02000321, 0.020003509, 0.91965...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>227</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>ENO</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>But indeed he has to live in holiness, for gr...</td>\n",
       "      <td>[0.02857527, 0.028575284, 0.028609488, 0.88566...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>228</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>KNC</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>But do we have to step in, still? Suicide, for...</td>\n",
       "      <td>[0.040126864, 0.8390767, 0.040464893, 0.040321...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>228</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>KNC</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>If someone kills themselves, by Sam's definit...</td>\n",
       "      <td>[0.022278167, 0.91074234, 0.022259397, 0.02246...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>229</td>\n",
       "      <td>Of Sin and Death</td>\n",
       "      <td>FIN</td>\n",
       "      <td>What sin leads to hell?</td>\n",
       "      <td>What about those who have heard of Jesus, who ...</td>\n",
       "      <td>[0.020056777, 0.0204873, 0.9194467, 0.02000404...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id       event_title speaker  \\\n",
       "0   205  Of Sin and Death     KNC   \n",
       "1   205  Of Sin and Death     KNC   \n",
       "2   206  Of Sin and Death     RIC   \n",
       "3   206  Of Sin and Death     RIC   \n",
       "4   207  Of Sin and Death     GRE   \n",
       "5   207  Of Sin and Death     GRE   \n",
       "6   208  Of Sin and Death      PY   \n",
       "7   208  Of Sin and Death      PY   \n",
       "8   209  Of Sin and Death     LIV   \n",
       "9   210  Of Sin and Death     TMS   \n",
       "10  210  Of Sin and Death     TMS   \n",
       "11  211  Of Sin and Death     LIV   \n",
       "12  211  Of Sin and Death     LIV   \n",
       "13  212  Of Sin and Death     RIC   \n",
       "14  213  Of Sin and Death     GRE   \n",
       "15  213  Of Sin and Death     GRE   \n",
       "16  213  Of Sin and Death     GRE   \n",
       "17  214  Of Sin and Death     GRE   \n",
       "18  215  Of Sin and Death    KSMG   \n",
       "19  216  Of Sin and Death     LIV   \n",
       "20  217  Of Sin and Death     LIV   \n",
       "21  217  Of Sin and Death     LIV   \n",
       "22  218  Of Sin and Death     GRE   \n",
       "23  218  Of Sin and Death     GRE   \n",
       "24  219  Of Sin and Death     SAM   \n",
       "25  220  Of Sin and Death     GRE   \n",
       "26  220  Of Sin and Death     GRE   \n",
       "27  220  Of Sin and Death     GRE   \n",
       "28  221  Of Sin and Death      PY   \n",
       "29  222  Of Sin and Death     LIV   \n",
       "30  222  Of Sin and Death     LIV   \n",
       "31  222  Of Sin and Death     LIV   \n",
       "32  223  Of Sin and Death     MAR   \n",
       "33  223  Of Sin and Death     MAR   \n",
       "34  223  Of Sin and Death     MAR   \n",
       "35  224  Of Sin and Death     SAM   \n",
       "36  224  Of Sin and Death     SAM   \n",
       "37  224  Of Sin and Death     SAM   \n",
       "38  225  Of Sin and Death     LIV   \n",
       "39  225  Of Sin and Death     LIV   \n",
       "40  226  Of Sin and Death     GRE   \n",
       "41  227  Of Sin and Death     ENO   \n",
       "42  227  Of Sin and Death     ENO   \n",
       "43  227  Of Sin and Death     ENO   \n",
       "44  227  Of Sin and Death     ENO   \n",
       "45  228  Of Sin and Death     KNC   \n",
       "46  228  Of Sin and Death     KNC   \n",
       "47  229  Of Sin and Death     FIN   \n",
       "\n",
       "                                             question  \\\n",
       "0   What is the difference between a mistake and a...   \n",
       "1   What is the difference between a mistake and a...   \n",
       "2   What is the difference between a mistake and a...   \n",
       "3   What is the difference between a mistake and a...   \n",
       "4   What is the difference between a mistake and a...   \n",
       "5   What is the difference between a mistake and a...   \n",
       "6   What is the difference between a mistake and a...   \n",
       "7   What is the difference between a mistake and a...   \n",
       "8   What is the difference between a mistake and a...   \n",
       "9   What is the difference between a mistake and a...   \n",
       "10  What is the difference between a mistake and a...   \n",
       "11  What is the difference between a mistake and a...   \n",
       "12  What is the difference between a mistake and a...   \n",
       "13  What is the difference between a mistake and a...   \n",
       "14  What is the difference between a mistake and a...   \n",
       "15  What is the difference between a mistake and a...   \n",
       "16  What is the difference between a mistake and a...   \n",
       "17  What is the difference between a mistake and a...   \n",
       "18  What is the difference between a mistake and a...   \n",
       "19  What is the difference between a mistake and a...   \n",
       "20  What is the difference between a mistake and a...   \n",
       "21  What is the difference between a mistake and a...   \n",
       "22  What is the difference between a mistake and a...   \n",
       "23  What is the difference between a mistake and a...   \n",
       "24                            What sin leads to hell?   \n",
       "25                            What sin leads to hell?   \n",
       "26                            What sin leads to hell?   \n",
       "27                            What sin leads to hell?   \n",
       "28                            What sin leads to hell?   \n",
       "29                            What sin leads to hell?   \n",
       "30                            What sin leads to hell?   \n",
       "31                            What sin leads to hell?   \n",
       "32                            What sin leads to hell?   \n",
       "33                            What sin leads to hell?   \n",
       "34                            What sin leads to hell?   \n",
       "35                            What sin leads to hell?   \n",
       "36                            What sin leads to hell?   \n",
       "37                            What sin leads to hell?   \n",
       "38                            What sin leads to hell?   \n",
       "39                            What sin leads to hell?   \n",
       "40                            What sin leads to hell?   \n",
       "41                            What sin leads to hell?   \n",
       "42                            What sin leads to hell?   \n",
       "43                            What sin leads to hell?   \n",
       "44                            What sin leads to hell?   \n",
       "45                            What sin leads to hell?   \n",
       "46                            What sin leads to hell?   \n",
       "47                            What sin leads to hell?   \n",
       "\n",
       "                                               answer  \\\n",
       "0                    A mistake isn't necessarily evil   \n",
       "1                                A sin is surely evil   \n",
       "2                  A sin is wicked in the eyes of god   \n",
       "3    A mistake isn't always wicked in the eyes of God   \n",
       "4                                Human error is a sin   \n",
       "5                          Everything improper is sin   \n",
       "6                  If a man defies a God then he sins   \n",
       "7    A mistake can be done by accident, but a sin ...   \n",
       "8      Maybe a sin is a mistake done with evil intent   \n",
       "9                                     Sin is commited   \n",
       "10                              Mistake is incidental   \n",
       "11  Sin is maybe knowing that your actions have co...   \n",
       "12   What then about a child that doesn't know any...   \n",
       "13  If a man marries a woman then abuses her, and ...   \n",
       "14                         A sin may not be a mistake   \n",
       "15                                 As an example, war   \n",
       "16   It depends on which theology to decide whethe...   \n",
       "17  If a man does wicked things while not being sa...   \n",
       "18  Is it still a sin if the sinner doesn't know t...   \n",
       "19           Yes, perhaps a sin but a forgivable one?   \n",
       "20                             I retract my statement   \n",
       "21   I said that a sin is \"forgiveable\", but I mea...   \n",
       "22                        It depends on one's resolve   \n",
       "23   Salvation comes from God and nary a man's act...   \n",
       "24                          If I choose to be in hell   \n",
       "25           Begging for forgiveness solves the trick   \n",
       "26   A mortal sin committed continuously, or a sin...   \n",
       "27        Some sins are harder to forgive than others   \n",
       "28  I think there are no sins that are greater or ...   \n",
       "29                           All sins are forgiveable   \n",
       "30   But in Catholicism, there are mortal sins tha...   \n",
       "31   These are sins that are very grave, such that...   \n",
       "32  All sin leads to death, and an eternal death i...   \n",
       "33   Even a trivial transgression or imperfection ...   \n",
       "34   It does not matter what your sin is; if you h...   \n",
       "35                         The sin of rejecting grace   \n",
       "36   Grace is offered by God, costing nothing, to ...   \n",
       "37   To know that it is offered to us with no char...   \n",
       "38                      All of us are bound to heaven   \n",
       "39               Nobody truly rejects God voluntarily   \n",
       "40  Salvation is God's decision, but humans contri...   \n",
       "41                                        God is Holy   \n",
       "42               Grace makes us live in a holy manner   \n",
       "43   There is no special treatment to eternal life...   \n",
       "44   But indeed he has to live in holiness, for gr...   \n",
       "45  But do we have to step in, still? Suicide, for...   \n",
       "46   If someone kills themselves, by Sam's definit...   \n",
       "47  What about those who have heard of Jesus, who ...   \n",
       "\n",
       "                                       Document Embed  Cluster Assignment  \n",
       "0   [0.040007103, 0.040260684, 0.5996429, 0.040007...                   0  \n",
       "1   [0.050733026, 0.05167625, 0.050830543, 0.05037...                   1  \n",
       "2   [0.04065759, 0.04073258, 0.83709264, 0.0403079...                   0  \n",
       "3   [0.02875328, 0.028849144, 0.029649774, 0.02880...                   1  \n",
       "4   [0.051153332, 0.05164998, 0.051087644, 0.05037...                   1  \n",
       "5   [0.050962675, 0.052271932, 0.050853908, 0.7952...                   2  \n",
       "6   [0.04075263, 0.041490786, 0.0412334, 0.835983,...                   2  \n",
       "7   [0.033426974, 0.8655161, 0.033683017, 0.033384...                   3  \n",
       "8   [0.033608258, 0.034077697, 0.033972435, 0.0334...                   1  \n",
       "9   [0.06717221, 0.73141354, 0.06747436, 0.0669311...                   3  \n",
       "10  [0.06667743, 0.06764174, 0.7308169, 0.06667845...                   0  \n",
       "11  [0.029023949, 0.02901999, 0.8844514, 0.0286515...                   0  \n",
       "12  [0.89954734, 0.02514468, 0.025158007, 0.025005...                   4  \n",
       "13  [0.018299364, 0.018419018, 0.018264854, 0.9267...                   2  \n",
       "14  [0.05024181, 0.7978977, 0.05078991, 0.05012995...                   3  \n",
       "15  [0.06668108, 0.06762332, 0.0666819, 0.73088604...                   2  \n",
       "16  [0.028575059, 0.028575044, 0.02857535, 0.02867...                   1  \n",
       "17  [0.8840682, 0.028986592, 0.028839175, 0.029245...                   4  \n",
       "18  [0.029255424, 0.8843754, 0.029063754, 0.028642...                   3  \n",
       "19  [0.86566013, 0.033727832, 0.033502348, 0.03352...                   4  \n",
       "20  [0.06668017, 0.066680245, 0.06668144, 0.733272...                   2  \n",
       "21  [0.9269299, 0.01836987, 0.018226681, 0.0182565...                   4  \n",
       "22  [0.050820436, 0.050006114, 0.050006703, 0.0503...                   1  \n",
       "23  [0.025198245, 0.8981943, 0.02571765, 0.0257437...                   3  \n",
       "24  [0.06741853, 0.06741675, 0.06667862, 0.0666788...                   1  \n",
       "25  [0.04000567, 0.040005684, 0.040006224, 0.04000...                   1  \n",
       "26  [0.025097737, 0.89940095, 0.025380086, 0.02505...                   3  \n",
       "27  [0.04032007, 0.041135516, 0.8381561, 0.0401693...                   0  \n",
       "28  [0.022592979, 0.91038305, 0.022374373, 0.02226...                   3  \n",
       "29  [0.06842044, 0.73050046, 0.06712451, 0.0669376...                   3  \n",
       "30  [0.040143333, 0.8395497, 0.04012863, 0.0400778...                   3  \n",
       "31  [0.0287198, 0.028934887, 0.8850192, 0.02865149...                   0  \n",
       "32  [0.89840376, 0.025333278, 0.025686143, 0.02536...                   4  \n",
       "33  [0.8856597, 0.028610762, 0.028576, 0.028576126...                   4  \n",
       "34  [0.86474687, 0.03445685, 0.033673394, 0.033532...                   4  \n",
       "35  [0.05055334, 0.05118644, 0.7952202, 0.05266554...                   0  \n",
       "36  [0.025127135, 0.025073422, 0.025245171, 0.8994...                   2  \n",
       "37  [0.9381442, 0.0154988635, 0.015440245, 0.01545...                   4  \n",
       "38  [0.05189561, 0.7975153, 0.050011735, 0.0505620...                   3  \n",
       "39  [0.033370886, 0.033371, 0.8664448, 0.0334253, ...                   0  \n",
       "40  [0.028716832, 0.028717935, 0.8851434, 0.028637...                   0  \n",
       "41  [0.06685794, 0.06685859, 0.73089373, 0.0684427...                   0  \n",
       "42  [0.028849918, 0.028688926, 0.028736042, 0.8851...                   2  \n",
       "43  [0.020260472, 0.02000321, 0.020003509, 0.91965...                   2  \n",
       "44  [0.02857527, 0.028575284, 0.028609488, 0.88566...                   2  \n",
       "45  [0.040126864, 0.8390767, 0.040464893, 0.040321...                   3  \n",
       "46  [0.022278167, 0.91074234, 0.022259397, 0.02246...                   3  \n",
       "47  [0.020056777, 0.0204873, 0.9194467, 0.02000404...                   0  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGoods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efebef93848af86820ba5c9af15e3b0ea109bf901e8b1e27dbaca7b722da8278"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
