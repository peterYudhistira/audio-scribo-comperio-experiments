{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports go here\n",
    "import numpy as np\n",
    "import db\n",
    "import pandas as pd\n",
    "import inflect\n",
    "import string\n",
    "import nltk\n",
    "import gensim\n",
    "import contractions\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora, models\n",
    "from nltk.test.gensim_fixt import setup_module\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# this is where everything we've experimented on will be implemented.\n",
    "\n",
    "\n",
    "class AnomalyDetector():\n",
    "    def __init__(self, dbName: str = \"\",  dh=None, model=None, modelName=\"glove-wiki-gigaword-300\") -> None:\n",
    "        if dh is None:\n",
    "            self.dh = db.DatabaseHandler(dbName=dbName)\n",
    "        else:\n",
    "            self.dh = dh\n",
    "        if model is None:\n",
    "            if modelName != \"\":\n",
    "                self.model = api.load(modelName)\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - dh : DatabaseHandler --> to retrieve data from database\n",
    "    - eventID : int --> we're doing this by event, so straight to the eventID\n",
    "    - selector : str --> pretty much formality.\n",
    "    - splitBySentences : bool --> Split each doc into sentences or not. Defaults to no.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    None, just setting\n",
    "    '''\n",
    "\n",
    "    def SetDFFromDB(self, dh: db.DatabaseHandler, eventID: int, selector: str = \"event_id\", splitBySentences: bool = False):\n",
    "        self.df = self.dh.get_recordDataJoinedDF(selector=selector, ID=eventID)\n",
    "        if splitBySentences:\n",
    "            # df.set_index('id', inplace=True)\n",
    "            self.df['answer'] = self.df['answer'].str.split('.')\n",
    "            self.df = self.df.explode(\"answer\", True)\n",
    "            self.df.drop(self.df[self.df[\"answer\"] == \"\"].index, inplace=True)\n",
    "            self.df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # ditto above, but takes a pre-made DF instead.\n",
    "    def SetDF(self, df:db.pd.DataFrame, splitBySentences:bool=False):\n",
    "        self.df = df\n",
    "        if splitBySentences:\n",
    "            # df.set_index('id', inplace=True)\n",
    "            self.df['answer'] = self.df['answer'].str.split('.')\n",
    "            self.df = self.df.explode(\"answer\", True)\n",
    "            self.df.drop(self.df[self.df[\"answer\"] == \"\"].index, inplace=True)\n",
    "            self.df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def SetModel(self, modelName:str=\"glove-wiki-gigaword-300\"):\n",
    "        self.model = api.load(modelName)\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - dh : DatabaseHandler --> to retrieve data from database\n",
    "    - eventID : int --> we're doing this by event, so straight to the eventID\n",
    "    - selector : str --> pretty much formality.\n",
    "    - splitBySentences : bool --> Split each doc into sentences or not. Defaults to no.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - df : DataFrame --> dataframe containing the thing we're gonna be using.\n",
    "    '''\n",
    "\n",
    "    def GetDF(self, dh: db.DatabaseHandler, eventID: int, selector: str = \"event_id\", splitBySentences: bool = False):\n",
    "        df = dh.get_recordDataJoinedDF(selector=selector, ID=eventID)\n",
    "        if splitBySentences:\n",
    "            # df.set_index('id', inplace=True)\n",
    "            df['answer'] = df['answer'].str.split('.')\n",
    "            df = df.explode(\"answer\", True)\n",
    "            df.drop(df[df[\"answer\"] == \"\"].index, inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - doc : str --> a string representing a sentence/document.\n",
    "    - isLemma : bool --> use lemmatizer or not? Defaults to not.\n",
    "    - isStopWords : bool --> use stopwords or not? Defaults to not.\n",
    "    - isInflect : bool --> use inflections (you're --> you are) or not? Defaults to not.\n",
    "    - isNumberFiltered :  bool --> delete numbers in the string? Defaults to yes. \n",
    "    '''\n",
    "    '''\n",
    "    output : list<str> --> a list of word tokens (list<string>)\n",
    "    '''\n",
    "\n",
    "    def PreprocessDocument(self, doc: str, isLemma: bool = False, isStopWords: bool = False, isInflect: bool = False, isNumberFiltered: bool = True):\n",
    "        inflector = inflect.engine()\n",
    "        stopwordSet = set(stopwords.words(\"english\"))\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        punctuations = string.punctuation\n",
    "        # if numbers are filtered, add that to the punctuation string\n",
    "        if isNumberFiltered:\n",
    "            punctuations += \"1234567890\"\n",
    "\n",
    "        # case fold\n",
    "        doc = doc.lower()\n",
    "\n",
    "        # remove puncs\n",
    "        doc = \"\".join([char for char in doc if char not in punctuations])\n",
    "\n",
    "        # tokenize it.\n",
    "        token_list = nltk.word_tokenize(doc)\n",
    "\n",
    "        for i in range(len(token_list)):\n",
    "            # if inflect\n",
    "            if isInflect:\n",
    "                if token_list[i].isdigit():\n",
    "                    token_list[i] = inflector.number_to_words(token_list[i])\n",
    "\n",
    "            # if lemma\n",
    "            if isLemma:\n",
    "                tagged_word = nltk.pos_tag([token_list[i]])\n",
    "                wordnet_pos = self.getWordnetPos(tagged_word[0][1])\n",
    "                token_list[i] = lemmatizer.lemmatize(\n",
    "                    tagged_word[0][0], pos=wordnet_pos)\n",
    "\n",
    "            # if stopword\n",
    "            if isStopWords:\n",
    "                if token_list[i] in stopwordSet or token_list[i].isdigit():\n",
    "                    token_list[i] = \"#\"  # mark as #\n",
    "\n",
    "        # remove the marked strings\n",
    "        token_list = [token for token in token_list if token != \"#\"]\n",
    "\n",
    "        if token_list:\n",
    "            return token_list\n",
    "        return [\"\"]\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - tag : str --> the tag obtained from POS tagging.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - str --> Wordnet POS tag.\n",
    "    '''\n",
    "\n",
    "    def getWordnetPos(self, tag):\n",
    "        \"\"\"Map POS tag to WordNet POS tag\"\"\"\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN  # solves as noun by default.\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - doclist : list<str> --> list of doc/sentences.\n",
    "    - isProcessed : bool --> has it already been preprocessed? Defaults to True.\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - df_tfidf : Dataframe --> the TFIDF matrix in df form. \n",
    "    - matrix : matrix --> the TFIDF matrix purely. mainly for LDA purposes.\n",
    "    '''\n",
    "\n",
    "    def GetTFIDF(self, doclist: list, isPreprocessed=True):\n",
    "        if not isPreprocessed:\n",
    "            doclist = [self.PreprocessDocument(\n",
    "                doc, isLemma=True, isStopWords=True) for doc in doclist]\n",
    "        # else:\n",
    "        #     # just tokenize the thing\n",
    "        #     doclist = [nltk.word_tokenize(doc) for doc in doclist]\n",
    "        # i think the thing has already been tokenized. That's the problem.\n",
    "        flat_doclist = [' '.join(doc)\n",
    "                        for doc in doclist]  # turn into one big corpus\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        matrix = vectorizer.fit_transform(flat_doclist)\n",
    "        tfidf_keys = vectorizer.get_feature_names_out()\n",
    "        df_tfidf = db.pd.DataFrame(matrix.toarray(), columns=tfidf_keys)\n",
    "\n",
    "        return df_tfidf, matrix\n",
    "\n",
    "    # input : list<str> : tokens of one document/sentence\n",
    "    # output : list<(str, list<int>[300])> : list of word-vector pair for each word available on the model\n",
    "    def WordEmbed(self, document: list, model):\n",
    "        word_embed_pairs = []\n",
    "        for word in document:\n",
    "            if word in model:\n",
    "                word_embed_pairs.append((word, model[word]))\n",
    "        return word_embed_pairs\n",
    "\n",
    "    # input : list<(str, list<float>[300])>, str : word-vector pair list and preferred agg method.\n",
    "    # output : list<float>[300] : 300-d vector that represents an aggregated value of the input words\n",
    "    def SentenceEmbedUnweightedFunction(self, word_embed_pair_list: list, aggregateMethod: str = \"avg\"):\n",
    "        wvs = []\n",
    "        for pair in word_embed_pair_list:\n",
    "            wvs.append(pair[1])\n",
    "        if aggregateMethod == \"avg\":\n",
    "            return np.mean(wvs, axis=0)\n",
    "        else:\n",
    "            return np.sum(wvs, axis=0)\n",
    "\n",
    "    # input : list<list<(str, list<float>[300])>>, str : list containing word-vector pairs and preferred agg method\n",
    "    # output : list<(str, list<int>[300])> : list containing sentence-vector pairs.\n",
    "    def SentenceEmbedUnweighted(self, word_embedded_docs: list, aggregateMethod: str = \"avg\"):\n",
    "        sentence_embedded_docs = []\n",
    "        for i in range(len(word_embedded_docs)):\n",
    "            sentence_embedded_docs.append(self.SentenceEmbedUnweightedFunction(\n",
    "                word_embedded_docs[i], aggregateMethod))\n",
    "        return sentence_embedded_docs\n",
    "\n",
    "    '''\n",
    "    input :\n",
    "    list<list<(str, list<float>[300])>> : word-vector pair list\n",
    "    matrix : tf-idf matrix for the corresponding doc\n",
    "    int : the row we want\n",
    "    str : preferred agg method\n",
    "    '''\n",
    "    # output : list<float>[300] : 300-d vector that represents an aggregated value of the input words\n",
    "\n",
    "    def SentenceEmbedWeightedFunction(self, word_embed_pair_list: list, tfidf_matrix, index: int, aggregateMethod: str = \"avg\"):\n",
    "        weighted_wvs = []\n",
    "        # multiplies each word with its TF-IDF value in the corresponding row. Is 0 if word isn't found somehow.\n",
    "        for pair in word_embed_pair_list:\n",
    "            tfidf_weight = 0\n",
    "            if pair[0] in tfidf_matrix:\n",
    "                tfidf_weight = tfidf_matrix[pair[0]][index]\n",
    "            weighted_wvs.append(pair[1] * tfidf_weight)\n",
    "        # turn into array for fast aggregating\n",
    "        weighted_wvs = np.array(weighted_wvs)\n",
    "        if aggregateMethod == \"avg\":\n",
    "            sentence_vector = np.mean(weighted_wvs, axis=0)\n",
    "        else:\n",
    "            sentence_vector = np.sum(weighted_wvs, axis=0)\n",
    "        return sentence_vector\n",
    "\n",
    "    # input : list<list<(str, list<float>[300])>>, str : list containing word-vector pairs, TF-IDF matrix of the corpus, and preferred agg method\n",
    "    # output : list<(str, list<float>[300])> : list containing sentence-vector pairs.\n",
    "    def SentenceEmbedWeighted(self, word_embedded_docs: list, tfidf_matrix, aggregateMethod=\"avg\"):\n",
    "        sentence_embedded_docs = []\n",
    "        for i in range(len(word_embedded_docs)):\n",
    "            sentence_embedded_docs.append(self.SentenceEmbedWeightedFunction(\n",
    "                word_embedded_docs[i], tfidf_matrix, i, aggregateMethod))\n",
    "        return sentence_embedded_docs\n",
    "\n",
    "    '''\n",
    "    input:\n",
    "    - doclist : list<list<str>> --> list of tokenized sentences/docs\n",
    "    - topics : int --> number of inferred topics.\n",
    "    - use_tfidf : bool --> use TFIDF or not? defaults to yes.\n",
    "    '''\n",
    "    '''\n",
    "    output:\n",
    "    - docFeatureList : list<list<float>> --> topic distribution for each sentence/doc\n",
    "    '''\n",
    "\n",
    "    def GetLDADistribution(self, doclist: list, topics: int = 5, use_tfidf: bool = True):\n",
    "        new_corpus = []\n",
    "\n",
    "        if use_tfidf:\n",
    "            for i in range(len(doclist)):\n",
    "                doc = [(j, self.tfidf_matrix[i, j])\n",
    "                       for j in self.tfidf_matrix[i].indices]\n",
    "                new_corpus.append(doc)\n",
    "                gensim_dict = corpora.Dictionary.from_corpus(new_corpus)\n",
    "        else:\n",
    "            gensim_dict = corpora.Dictionary(doclist)\n",
    "            new_corpus = [gensim_dict.doc2bow(doc) for doc in doclist]\n",
    "\n",
    "        lda_model = gensim.models.LdaModel(\n",
    "            new_corpus, num_topics=topics, id2word=gensim_dict)\n",
    "        goofy_ahh_doc_topic_distributions = lda_model[new_corpus]\n",
    "\n",
    "        docFeatureList = []\n",
    "        for doc_topic_dist in goofy_ahh_doc_topic_distributions:\n",
    "            featureList = [0.0 for i in range(0, topics)]\n",
    "            for topic_dist in doc_topic_dist:\n",
    "                featureList[topic_dist[0]] = topic_dist[1]\n",
    "            docFeatureList.append(featureList)\n",
    "\n",
    "        return docFeatureList\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - vectors : list<list<float>> --> list of features corresponding to each doc/sentence\n",
    "    - epsilon : float --> the radius within which points are considered connected.\n",
    "    - min : int --> minimum amount of connected points for a point to be considered a core point of a cluster.\n",
    "    '''\n",
    "    '''\n",
    "    output:\n",
    "    clusters : list<int> --> a list of integers to assign each data point to a cluster. -1 means outlier.\n",
    "    '''\n",
    "\n",
    "    def GetDBSCANClusters(self, vectors, epsilon: float, min: int):\n",
    "        dbscan = DBSCAN(eps=epsilon, min_samples=min)\n",
    "        clusters = dbscan.fit_predict(vectors)\n",
    "        # plt.title(\"to the depths of depravity {} and the cusp of blasphemy {}.\".format(epsilon, min))\n",
    "        # plt.scatter(vectors[:, 0], vectors[:, 1], c=clusters)\n",
    "        # plt.show()\n",
    "        # print(clusters)\n",
    "        return clusters\n",
    "\n",
    "    '''\n",
    "    inputs :\n",
    "    - clusters : list<int> --> a list of clusters assigned to each doc/sentence\n",
    "    - df : DataFrame --> the dataframe in question\n",
    "    - isReturnSeparate : bool --> split return or not. Defaults to split (for some reason...)\n",
    "    '''\n",
    "    '''\n",
    "    outputs:\n",
    "    - dfOutliers : DataFrame --> the dataframe whose answers have been marked as outliers.\n",
    "    - dfGoods : DataFrame --> the dataframe whose answers have not been marked as outliers.\n",
    "    '''\n",
    "\n",
    "    def ReturnClusters(self, clusters: list, df: db.pd.DataFrame, isReturnSeparate:bool=True):\n",
    "        df[\"Cluster Assignment\"] = clusters\n",
    "        if isReturnSeparate:\n",
    "            dfGoods = df.loc[df[\"Cluster Assignment\"] != -1]\n",
    "            dfOutliers = df.loc[df[\"Cluster Assignment\"] == -1]\n",
    "            return dfOutliers, dfGoods\n",
    "        else:\n",
    "            df.reset_index(inplace=True)\n",
    "            return df\n",
    "\n",
    "    '''\n",
    "    inputs:\n",
    "    - method : str --> LDA or Embedding.\n",
    "    - isWeighted : bool --> use weights or not\n",
    "    - nTopics : int --> for LDA.\n",
    "    '''\n",
    "    '''\n",
    "    - outputs : none. This is an internal function\n",
    "    '''\n",
    "    def ExtractFeatures(self, method:str=\"LDA\", isWeighted:bool=True, nTopics:int=5, aggregateMethod:str=\"avg\"):\n",
    "        if method == \"LDA\":\n",
    "            # if weighted, prepare tf-idf matrix.\n",
    "            if isWeighted:\n",
    "                self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                    self.preprocessedDocs)\n",
    "\n",
    "            # use the in-house options for weighted or not.\n",
    "            self.doc_embeds = self.GetLDADistribution(\n",
    "                self.preprocessedDocs, topics=nTopics, use_tfidf=isWeighted)\n",
    "        else:\n",
    "            # if weighted, prepare TF-IDF and embed sentences with weight.\n",
    "            if isWeighted:\n",
    "                self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                    self.preprocessedDocs)\n",
    "                self.doc_embeds = self.SentenceEmbedWeighted(\n",
    "                    self.wordEmbeddedDocs, self.tfidf_df, aggregateMethod)\n",
    "            else:\n",
    "                self.doc_embeds = self.SentenceEmbedUnweighted(\n",
    "                    self.wordEmbeddedDocs, aggregateMethod)\n",
    "                                                                                                         \n",
    "\n",
    "    def GetAnomalies_DBSCAN_Embedding(self, isWeighted: bool = True, aggregateMethod: str = \"avg\", epsilon: float = 0.01, minsamp: int = 2, isReturnSeparate:bool=True):\n",
    "        # df and model are obtained by invoking a separate function, and it is assumed to be already available when invoking this function.\n",
    "\n",
    "        # preprocess each doc/sentence\n",
    "        self.preprocessedDocs = [self.PreprocessDocument(\n",
    "            doc, isLemma=True, isStopWords=True) for doc in self.df[\"answer\"]]\n",
    "\n",
    "        # extract feature with embedding\n",
    "        self.wordEmbeddedDocs = [self.WordEmbed(\n",
    "            doc, self.model) for doc in self.preprocessedDocs]\n",
    "\n",
    "        # if weighted, prepare TF-IDF and embed sentences with weight.\n",
    "        if isWeighted:\n",
    "            self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                self.preprocessedDocs)\n",
    "            self.doc_embeds = self.SentenceEmbedWeighted(\n",
    "                self.wordEmbeddedDocs, self.tfidf_df, aggregateMethod)\n",
    "        else:\n",
    "            self.doc_embeds = self.SentenceEmbedUnweighted(\n",
    "                self.wordEmbeddedDocs, aggregateMethod)\n",
    "\n",
    "        # append embedding to each document\n",
    "        if self.doc_embeds:\n",
    "            self.df[\"Document Embed\"] = self.doc_embeds\n",
    "            self.df = self.df.dropna(subset=[\"Document Embed\"]) # preventing NaN in the simplest fucking way in know.\n",
    "\n",
    "        # apply DBSCAN\n",
    "        self.clusters = self.GetDBSCANClusters(\n",
    "            list(self.df[\"Document Embed\"]), epsilon, minsamp)\n",
    "\n",
    "        # return the dfs\n",
    "        return self.ReturnClusters(self.clusters, self.df, isReturnSeparate=isReturnSeparate)\n",
    "\n",
    "    def GetAnomalies_DBSCAN_LDA(self, isWeighted: bool = True, topics: int = 5, epsilon: float = 0.01, minsamp: int = 5, isReturnSeparate:bool=True):\n",
    "        # df and model are obtained by invoking a separate function, and it is assumed to be already available when invoking this function.\n",
    "\n",
    "        # preprocess each doc/sentence\n",
    "        self.preprocessedDocs = [self.PreprocessDocument(\n",
    "            doc, isLemma=True, isStopWords=True) for doc in self.df[\"answer\"]]\n",
    "\n",
    "        # if weighted, prepare tf-idf matrix.\n",
    "        if isWeighted:\n",
    "            self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                self.preprocessedDocs)\n",
    "\n",
    "        # use the in-house options for weighted or not.\n",
    "        self.doc_embeds = self.GetLDADistribution(\n",
    "            self.preprocessedDocs, topics=topics, use_tfidf=isWeighted)\n",
    "\n",
    "        # append embedding to each document\n",
    "        if self.doc_embeds:\n",
    "            self.df[\"Document Embed\"] = self.doc_embeds\n",
    "            self.df = self.df.dropna(subset=[\"Document Embed\"]) # preventing NaN in the simplest fucking way in know.\n",
    "\n",
    "        # apply DBSCAN\n",
    "        self.clusters = self.GetDBSCANClusters(\n",
    "            list(self.df[\"Document Embed\"]), epsilon, minsamp)\n",
    "\n",
    "        # return the dfs\n",
    "        return self.ReturnClusters(self.clusters, self.df, isReturnSeparate=isReturnSeparate)\n",
    "\n",
    "    def GetAnomalies(self, method: str, model, isWeighted: bool = True, aggregateMethod: str = \"avg\", epsilon=0.01, minsamp=2, topics=5):\n",
    "        # initialize\n",
    "        # extract the dataset\n",
    "        self.df = self.GetDF()\n",
    "    \n",
    "    def GetAnomalies_IsolationForest_Embedding(self, isWeighted:bool=True, aggregateMethod:str=\"avg\", isReturnSeparate:bool=True):\n",
    "        # df and model are obtained by invoking a separate function, and it is assumed to be already available when invoking this function.\n",
    "\n",
    "        # preprocess each doc/sentence\n",
    "        self.preprocessedDocs = [self.PreprocessDocument(\n",
    "            doc, isLemma=True, isStopWords=True) for doc in self.df[\"answer\"]]\n",
    "\n",
    "        # extract feature with embedding\n",
    "        self.wordEmbeddedDocs = [self.WordEmbed(\n",
    "            doc, self.model) for doc in self.preprocessedDocs]\n",
    "\n",
    "        # if weighted, prepare TF-IDF and embed sentences with weight.\n",
    "        if isWeighted:\n",
    "            self.tfidf_df, self.tfidf_matrix = self.GetTFIDF(\n",
    "                self.preprocessedDocs)\n",
    "            self.doc_embeds = self.SentenceEmbedWeighted(\n",
    "                self.wordEmbeddedDocs, self.tfidf_df, aggregateMethod)\n",
    "        else:\n",
    "            self.doc_embeds = self.SentenceEmbedUnweighted(\n",
    "                self.wordEmbeddedDocs, aggregateMethod)\n",
    "\n",
    "        # append embedding to each document\n",
    "        if self.doc_embeds:\n",
    "            self.df[\"Document Embed\"] = self.doc_embeds\n",
    "            self.df = self.df.dropna(subset=[\"Document Embed\"]) # preventing NaN in the simplest fucking way in know.\n",
    "        \n",
    "        # apply Isolation Forest\n",
    "        self.ifResults = self.GetIFResults(vector=list(self.df[\"Document Embed\"]))\n",
    "\n",
    "        return self.ReturnClusters(self.ifResults, self.df, isReturnSeparate=isReturnSeparate)\n",
    "        \n",
    "\n",
    "    def GetIFResults(self, vector):\n",
    "        isolationForest = IsolationForest(n_estimators=100, contamination=0.1)\n",
    "        isolationForest.fit(vector)\n",
    "        IFResults = isolationForest.decision_function(vector)\n",
    "\n",
    "        # minus values yield anomalies.\n",
    "        for i in range(len(IFResults)):\n",
    "            if IFResults[i] >= 0:\n",
    "                IFResults[i] = 0\n",
    "            else:\n",
    "                IFResults[i] = -1\n",
    "        return IFResults\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = db.DatabaseHandler(\"testdb.db\")\n",
    "ad = AnomalyDetector(dh=dh, modelName=\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.SetDFFromDB(ad.dh, 18, splitBySentences=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Document Embed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>PY</td>\n",
       "      <td>How did we come to exist?</td>\n",
       "      <td>It is not by my hand that I was once again gi...</td>\n",
       "      <td>[-0.037256964, -0.005106877, -0.014977815, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>How did we come to exist?</td>\n",
       "      <td>Even if a thousand men fall at your side and ...</td>\n",
       "      <td>[-0.020165913, 0.013082339, -0.014995785, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>PY</td>\n",
       "      <td>Do you think you need to exist?</td>\n",
       "      <td>We don't really need to exist. Even if I don't...</td>\n",
       "      <td>[-0.042173408, 0.023831157, -0.027844723, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Do you think you need to exist?</td>\n",
       "      <td>I don't think we need to exist. As Peter said,...</td>\n",
       "      <td>[-0.03246461, 0.012234184, -0.014134587, 0.040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>TMS</td>\n",
       "      <td>Do you think you need to exist?</td>\n",
       "      <td>I think we are a part of a bigger picture.</td>\n",
       "      <td>[-0.003818011, 0.05617611, -0.049015313, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>TMS</td>\n",
       "      <td>Do you think you need to exist?</td>\n",
       "      <td>Yes, because we're a part of a community where...</td>\n",
       "      <td>[-0.037814233, -0.048823945, -0.019741789, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>DJ</td>\n",
       "      <td>Do you think you need to exist?</td>\n",
       "      <td>In general,  humans have made many impacts. Th...</td>\n",
       "      <td>[0.038543474, 0.02189518, -0.03183997, -0.0730...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>RIC</td>\n",
       "      <td>Do you think you need to exist?</td>\n",
       "      <td>This got me thinking, if we question the purpo...</td>\n",
       "      <td>[-0.04423244, -0.00738029, -0.009012498, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>It's a mystery. We won't know. Religion said s...</td>\n",
       "      <td>[-0.023103386, -0.0318319, -0.05187923, -0.011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>TMS</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>I think God himself needs an outlet to His lov...</td>\n",
       "      <td>[-0.06028241, -0.038177412, -0.0744806, -0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>RIC</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>God created us to glorify Him.</td>\n",
       "      <td>[0.016429748, 0.03783902, -0.17264646, -0.0365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>PAU</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>God is full of mysteries. How should I know.</td>\n",
       "      <td>[-0.10444261, -0.038591, 0.026160572, -0.03644...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>PAU</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>I too believe that humans are created for a pu...</td>\n",
       "      <td>[-0.07501761, 0.07945418, -0.15191446, -0.1044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>LIZ</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>Maybe because God is a relational being, so He...</td>\n",
       "      <td>[-0.16343288, -0.010339371, -0.010692698, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>RIC</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>I reckon God created humans so the world would...</td>\n",
       "      <td>[-0.0038416332, 0.11715726, -0.09831815, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>AMD</td>\n",
       "      <td>Does God need to be glorified?</td>\n",
       "      <td>if we are indeed created to glorify Him, does ...</td>\n",
       "      <td>[0.031829923, 0.089677684, -0.103754185, 0.013...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>TMS</td>\n",
       "      <td>Does God need to be glorified?</td>\n",
       "      <td>i think if that's the only reason for humans t...</td>\n",
       "      <td>[0.004605764, -0.031550776, -0.03918793, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>YOR</td>\n",
       "      <td>Does God need to be glorified?</td>\n",
       "      <td>If worship is a response to God, then did God ...</td>\n",
       "      <td>[-0.04870874, -0.097334325, -0.020691205, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>AUD</td>\n",
       "      <td>Does God need to be glorified?</td>\n",
       "      <td>God doesn't require praise. But He does long f...</td>\n",
       "      <td>[-0.028303271, -0.04729459, -0.040874172, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>TMS</td>\n",
       "      <td>If there is a creator, How would the creator b...</td>\n",
       "      <td>All the good things that we know are of His cr...</td>\n",
       "      <td>[0.013166753, -0.025942568, 0.024918566, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>If there is a creator, How would the creator b...</td>\n",
       "      <td>The creator would be a dictator of value then,...</td>\n",
       "      <td>[-0.083122216, 0.07205174, -0.007381319, 0.021...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>AMD</td>\n",
       "      <td>If there is a creator, How would the creator b...</td>\n",
       "      <td>God would have been righteous by default. Ever...</td>\n",
       "      <td>[-0.005705846, 0.044494636, 0.0081070075, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>If there is a creator, How would the creator b...</td>\n",
       "      <td>A dictator is still a dictator. If a person do...</td>\n",
       "      <td>[0.0025683239, -0.042591646, 0.008026343, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>TMS</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>Unholiness is the output of free will. It is t...</td>\n",
       "      <td>[-0.05987806, 0.05340756, -0.036931742, -0.069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>ANT</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>Maybe because there would be balance in a cert...</td>\n",
       "      <td>[0.036639832, 0.039184604, -0.07707711, -0.114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>YOR</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>Holiness is a character. Creating something po...</td>\n",
       "      <td>[-0.06158311, -0.0024161104, -0.04745406, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>This concept is too Christian.</td>\n",
       "      <td>[-0.05881997, -0.08591559, -0.19163653, 0.0403...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>SAM</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>Why is love not objective then?</td>\n",
       "      <td>[-0.109933846, 0.06672216, 0.037460387, -0.148...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>Because not everbody understands the concept o...</td>\n",
       "      <td>[-0.10131706, -0.05622952, -0.007367739, 0.049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>77</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>G-RAT</td>\n",
       "      <td>What do you think a man is?</td>\n",
       "      <td>It is not by my hand that I was once again gi...</td>\n",
       "      <td>[-0.037256964, -0.005106877, -0.014977815, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>78</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>YOT</td>\n",
       "      <td>Psalm 91:7-9</td>\n",
       "      <td>Even if a thousand men fall at your side and ...</td>\n",
       "      <td>[-0.020165913, 0.013082339, -0.014995785, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id             event_title speaker  \\\n",
       "0    1  Why Did God Create Us?      PY   \n",
       "1    2  Why Did God Create Us?     GRE   \n",
       "2    3  Why Did God Create Us?      PY   \n",
       "3    4  Why Did God Create Us?      JJ   \n",
       "4    5  Why Did God Create Us?     TMS   \n",
       "5    6  Why Did God Create Us?     TMS   \n",
       "6    7  Why Did God Create Us?      DJ   \n",
       "7    8  Why Did God Create Us?     RIC   \n",
       "8    9  Why Did God Create Us?     GRE   \n",
       "9   10  Why Did God Create Us?     TMS   \n",
       "10  11  Why Did God Create Us?     RIC   \n",
       "11  12  Why Did God Create Us?     PAU   \n",
       "12  13  Why Did God Create Us?     PAU   \n",
       "13  14  Why Did God Create Us?     LIZ   \n",
       "14  15  Why Did God Create Us?     RIC   \n",
       "15  16  Why Did God Create Us?     AMD   \n",
       "16  17  Why Did God Create Us?     TMS   \n",
       "17  18  Why Did God Create Us?     YOR   \n",
       "18  19  Why Did God Create Us?     AUD   \n",
       "19  20  Why Did God Create Us?     TMS   \n",
       "20  21  Why Did God Create Us?     GRE   \n",
       "21  22  Why Did God Create Us?     AMD   \n",
       "22  23  Why Did God Create Us?     GRE   \n",
       "23  24  Why Did God Create Us?     TMS   \n",
       "24  25  Why Did God Create Us?     ANT   \n",
       "25  26  Why Did God Create Us?     YOR   \n",
       "26  27  Why Did God Create Us?     GRE   \n",
       "27  28  Why Did God Create Us?     SAM   \n",
       "28  29  Why Did God Create Us?     GRE   \n",
       "29  77  Why Did God Create Us?   G-RAT   \n",
       "30  78  Why Did God Create Us?     YOT   \n",
       "\n",
       "                                             question  \\\n",
       "0                           How did we come to exist?   \n",
       "1                           How did we come to exist?   \n",
       "2                     Do you think you need to exist?   \n",
       "3                     Do you think you need to exist?   \n",
       "4                     Do you think you need to exist?   \n",
       "5                     Do you think you need to exist?   \n",
       "6                     Do you think you need to exist?   \n",
       "7                     Do you think you need to exist?   \n",
       "8   From a bigger perspective, why did God create us?   \n",
       "9   From a bigger perspective, why did God create us?   \n",
       "10  From a bigger perspective, why did God create us?   \n",
       "11  From a bigger perspective, why did God create us?   \n",
       "12  From a bigger perspective, why did God create us?   \n",
       "13  From a bigger perspective, why did God create us?   \n",
       "14  From a bigger perspective, why did God create us?   \n",
       "15                     Does God need to be glorified?   \n",
       "16                     Does God need to be glorified?   \n",
       "17                     Does God need to be glorified?   \n",
       "18                     Does God need to be glorified?   \n",
       "19  If there is a creator, How would the creator b...   \n",
       "20  If there is a creator, How would the creator b...   \n",
       "21  If there is a creator, How would the creator b...   \n",
       "22  If there is a creator, How would the creator b...   \n",
       "23  Why would a Holy God create a creation that ha...   \n",
       "24  Why would a Holy God create a creation that ha...   \n",
       "25  Why would a Holy God create a creation that ha...   \n",
       "26  Why would a Holy God create a creation that ha...   \n",
       "27  Why would a Holy God create a creation that ha...   \n",
       "28  Why would a Holy God create a creation that ha...   \n",
       "29                        What do you think a man is?   \n",
       "30                                       Psalm 91:7-9   \n",
       "\n",
       "                                               answer  \\\n",
       "0    It is not by my hand that I was once again gi...   \n",
       "1    Even if a thousand men fall at your side and ...   \n",
       "2   We don't really need to exist. Even if I don't...   \n",
       "3   I don't think we need to exist. As Peter said,...   \n",
       "4          I think we are a part of a bigger picture.   \n",
       "5   Yes, because we're a part of a community where...   \n",
       "6   In general,  humans have made many impacts. Th...   \n",
       "7   This got me thinking, if we question the purpo...   \n",
       "8   It's a mystery. We won't know. Religion said s...   \n",
       "9   I think God himself needs an outlet to His lov...   \n",
       "10                     God created us to glorify Him.   \n",
       "11      God is full of mysteries. How should I know.    \n",
       "12  I too believe that humans are created for a pu...   \n",
       "13  Maybe because God is a relational being, so He...   \n",
       "14  I reckon God created humans so the world would...   \n",
       "15  if we are indeed created to glorify Him, does ...   \n",
       "16  i think if that's the only reason for humans t...   \n",
       "17  If worship is a response to God, then did God ...   \n",
       "18  God doesn't require praise. But He does long f...   \n",
       "19  All the good things that we know are of His cr...   \n",
       "20  The creator would be a dictator of value then,...   \n",
       "21  God would have been righteous by default. Ever...   \n",
       "22  A dictator is still a dictator. If a person do...   \n",
       "23  Unholiness is the output of free will. It is t...   \n",
       "24  Maybe because there would be balance in a cert...   \n",
       "25  Holiness is a character. Creating something po...   \n",
       "26                     This concept is too Christian.   \n",
       "27                    Why is love not objective then?   \n",
       "28  Because not everbody understands the concept o...   \n",
       "29   It is not by my hand that I was once again gi...   \n",
       "30   Even if a thousand men fall at your side and ...   \n",
       "\n",
       "                                       Document Embed  \n",
       "0   [-0.037256964, -0.005106877, -0.014977815, -0....  \n",
       "1   [-0.020165913, 0.013082339, -0.014995785, -0.0...  \n",
       "2   [-0.042173408, 0.023831157, -0.027844723, 0.02...  \n",
       "3   [-0.03246461, 0.012234184, -0.014134587, 0.040...  \n",
       "4   [-0.003818011, 0.05617611, -0.049015313, -0.08...  \n",
       "5   [-0.037814233, -0.048823945, -0.019741789, -0....  \n",
       "6   [0.038543474, 0.02189518, -0.03183997, -0.0730...  \n",
       "7   [-0.04423244, -0.00738029, -0.009012498, -0.03...  \n",
       "8   [-0.023103386, -0.0318319, -0.05187923, -0.011...  \n",
       "9   [-0.06028241, -0.038177412, -0.0744806, -0.008...  \n",
       "10  [0.016429748, 0.03783902, -0.17264646, -0.0365...  \n",
       "11  [-0.10444261, -0.038591, 0.026160572, -0.03644...  \n",
       "12  [-0.07501761, 0.07945418, -0.15191446, -0.1044...  \n",
       "13  [-0.16343288, -0.010339371, -0.010692698, -0.0...  \n",
       "14  [-0.0038416332, 0.11715726, -0.09831815, -0.05...  \n",
       "15  [0.031829923, 0.089677684, -0.103754185, 0.013...  \n",
       "16  [0.004605764, -0.031550776, -0.03918793, -0.01...  \n",
       "17  [-0.04870874, -0.097334325, -0.020691205, -0.0...  \n",
       "18  [-0.028303271, -0.04729459, -0.040874172, -0.0...  \n",
       "19  [0.013166753, -0.025942568, 0.024918566, -0.06...  \n",
       "20  [-0.083122216, 0.07205174, -0.007381319, 0.021...  \n",
       "21  [-0.005705846, 0.044494636, 0.0081070075, -0.0...  \n",
       "22  [0.0025683239, -0.042591646, 0.008026343, -0.1...  \n",
       "23  [-0.05987806, 0.05340756, -0.036931742, -0.069...  \n",
       "24  [0.036639832, 0.039184604, -0.07707711, -0.114...  \n",
       "25  [-0.06158311, -0.0024161104, -0.04745406, -0.0...  \n",
       "26  [-0.05881997, -0.08591559, -0.19163653, 0.0403...  \n",
       "27  [-0.109933846, 0.06672216, 0.037460387, -0.148...  \n",
       "28  [-0.10131706, -0.05622952, -0.007367739, 0.049...  \n",
       "29  [-0.037256964, -0.005106877, -0.014977815, -0....  \n",
       "30  [-0.020165913, 0.013082339, -0.014995785, -0.0...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>event_title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>Document Embed</th>\n",
       "      <th>Cluster Assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>It's a mystery</td>\n",
       "      <td>[-0.17551, -0.082361, 0.35437, 0.057444, 0.627...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>Religion said so, but then it is religion, no...</td>\n",
       "      <td>[-0.067476034, -0.18543604, -0.1247678, 0.0038...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>PAU</td>\n",
       "      <td>From a bigger perspective, why did God create us?</td>\n",
       "      <td>How should I know</td>\n",
       "      <td>[-0.21054, 0.1382, 0.035328, 0.03977, -0.10913...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>If there is a creator, How would the creator b...</td>\n",
       "      <td>A dictator is still a dictator</td>\n",
       "      <td>[0.028574442, -0.33913907, 0.25452283, -0.5800...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>54</td>\n",
       "      <td>23</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>If there is a creator, How would the creator b...</td>\n",
       "      <td>This is how dictatorship works</td>\n",
       "      <td>[0.17178635, 0.06104046, -0.026714057, -0.2459...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>ANT</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>I am unsure of what aspect it is</td>\n",
       "      <td>[0.03384018, 0.05262956, -0.0057979524, -0.195...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>YOR</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>Holiness is a character</td>\n",
       "      <td>[-0.23910463, -0.06778326, -0.1642397, -0.1269...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>62</td>\n",
       "      <td>27</td>\n",
       "      <td>Why Did God Create Us?</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Why would a Holy God create a creation that ha...</td>\n",
       "      <td>This concept is too Christian</td>\n",
       "      <td>[-0.05881997, -0.08591559, -0.19163653, 0.0403...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  id             event_title speaker  \\\n",
       "28     29   9  Why Did God Create Us?     GRE   \n",
       "30     31   9  Why Did God Create Us?     GRE   \n",
       "35     36  12  Why Did God Create Us?     PAU   \n",
       "50     52  23  Why Did God Create Us?     GRE   \n",
       "52     54  23  Why Did God Create Us?     GRE   \n",
       "56     58  25  Why Did God Create Us?     ANT   \n",
       "57     59  26  Why Did God Create Us?     YOR   \n",
       "60     62  27  Why Did God Create Us?     GRE   \n",
       "\n",
       "                                             question  \\\n",
       "28  From a bigger perspective, why did God create us?   \n",
       "30  From a bigger perspective, why did God create us?   \n",
       "35  From a bigger perspective, why did God create us?   \n",
       "50  If there is a creator, How would the creator b...   \n",
       "52  If there is a creator, How would the creator b...   \n",
       "56  Why would a Holy God create a creation that ha...   \n",
       "57  Why would a Holy God create a creation that ha...   \n",
       "60  Why would a Holy God create a creation that ha...   \n",
       "\n",
       "                                               answer  \\\n",
       "28                                     It's a mystery   \n",
       "30   Religion said so, but then it is religion, no...   \n",
       "35                                  How should I know   \n",
       "50                     A dictator is still a dictator   \n",
       "52                     This is how dictatorship works   \n",
       "56                   I am unsure of what aspect it is   \n",
       "57                            Holiness is a character   \n",
       "60                      This concept is too Christian   \n",
       "\n",
       "                                       Document Embed  Cluster Assignment  \n",
       "28  [-0.17551, -0.082361, 0.35437, 0.057444, 0.627...                -1.0  \n",
       "30  [-0.067476034, -0.18543604, -0.1247678, 0.0038...                -1.0  \n",
       "35  [-0.21054, 0.1382, 0.035328, 0.03977, -0.10913...                -1.0  \n",
       "50  [0.028574442, -0.33913907, 0.25452283, -0.5800...                -1.0  \n",
       "52  [0.17178635, 0.06104046, -0.026714057, -0.2459...                -1.0  \n",
       "56  [0.03384018, 0.05262956, -0.0057979524, -0.195...                -1.0  \n",
       "57  [-0.23910463, -0.06778326, -0.1642397, -0.1269...                -1.0  \n",
       "60  [-0.05881997, -0.08591559, -0.19163653, 0.0403...                -1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly, good = ad.GetAnomalies_IsolationForest_Embedding(isWeighted=True, aggregateMethod=\"avg\", isReturnSeparate=True)\n",
    "anomaly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
